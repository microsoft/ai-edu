<!--Copyright © Microsoft Corporation. All rights reserved.
  适用于[License](https://github.com/Microsoft/ai-edu/blob/master/LICENSE.md)版权许可-->

## 14.3 Functional test of binary classification tasks

### 14.3.1 Build a model

This is also a two-layer neural network. However, the last layer needs to be connected to a logistic two-classification function to complete the binary classification task, as shown in Figure 14-7.

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/14/ch10_net.png" />

Figure 14-7 The complete abstract model of the non-linear two-category teaching case

```Python

def model(dataReader):
    num_input = 2
    num_hidden = 3
    num_output = 1

    max_epoch = 1000
    batch_size = 5
    learning_rate = 0.1

    params = HyperParameters_4_0(
        learning_rate, max_epoch, batch_size,
        net_type=NetType.BinaryClassifier,
        init_method=InitialMethod.Xavier,
        stopper=Stopper(StopCondition.StopLoss, 0.02))

    net = NeuralNet_4_0(params, "Arc")

    fc1 = FcLayer_1_0(num_input, num_hidden, params)
    net.add_layer(fc1, "fc1")
    sigmoid1 = ActivationLayer(Sigmoid())
    net.add_layer(sigmoid1, "sigmoid1")
    
    fc2 = FcLayer_1_0(num_hidden, num_output, params)
    net.add_layer(fc2, "fc2")
    logistic = ClassificationLayer(Logistic())
    net.add_layer(logistic, "logistic")

    net.train(dataReader, checkpoint=10, need_test=True)
    return net
```

Hyperparameter description: 

1. The number of neurons in the input layer is 2
2. The number of neurons in the hidden layer is 3, using the sigmoid activation function
3. Since it is a binary classification task, the output layer has one neuron, and the logistic binary classification function is used
4. Up to 1000 rounds of training
5. Batch size = 5
6. Learning rate = 0.1
7. Absolute error stop condition = 0.02  

### 14.3.2 Results of execution

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/14/ch10_loss.png" />

Figure 14-8 Changes in loss function value and accuracy during training

Figure 14-8 is a record of the training. Take a look at the following output:

```
......
epoch=419, total_iteration=30239
loss_train=0.010094, accuracy_train=1.000000
loss_valid=0.019141, accuracy_valid=1.000000
time used: 2.149379253387451
testing...
1.0
```

The result of the final test is 1.0, which means that it is 100% correct. This shows that the mini framework works very well in this basic case. The classification shown in Figure 14-9 is also good. 

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/14/ch10_result.png" ch="500" />

Figure 14-9 Classification effect

### Code location 

ch14, Level3
