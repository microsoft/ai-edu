Copyright © Microsoft Corporation. All rights reserved.
  适用于[License](https://github.com/Microsoft/ai-edu/blob/master/LICENSE.md)版权许可

# 知识点

- [数据集使用之验证与测试](10.1-数据集使用之验证与测试.md)
- [三层神经网络的实现](10.2-三层神经网络的实现.md)
- [梯度检查](10.3-梯度检查.md)
- [手工测试训练效果](10.4-手工测试训练效果.md)

# 提出问题

手写识别是人工智能的重要课题之一。MNIST数字手写体识别图片集，大家一定不陌生，下面就是一些样本。

<img src='./Images/12/Mnist.png'/>

由于这是从欧美收集的数据，从图中可以看出有几点和中国人的手写习惯不一样：

- 数字2，下面多一个圈
- 数字4，很多横线不出头
- 数字6，上面是直的
- 数字7，中间有个横杠

不过这些细节不影响咱们学习课程，正好还可以验证一下中国人的手写习惯是否能够被正确识别。

由于不是让我们识别26个英文字母或者3500多个常用汉字，所以问题还算是比较简单，不需要图像处理只是。咱们可以试试用一个两三层的神经网络能不能解决，把每个图片的像素都当作一个向量来看，而不是作为点阵。

# 下载训练数据

MNIST数字手写体识别图片集，大家一定不陌生，[这是该网站的地址](http://yann.lecun.com/exdb/mnist/)。但是从上述地址下载的文件是压缩的，在解压缩过程中很可能会出现意想不到的问题，比如长度不对，后面补零等等，所以我们也准备了解压缩好的数据。

[点击下载训练及标签数据](https://github.com/Microsoft/ai-edu/tree/master/B-%E6%95%99%E5%AD%A6%E6%A1%88%E4%BE%8B%E4%B8%8E%E5%AE%9E%E8%B7%B5/B6-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%E7%AE%80%E6%98%8E%E6%95%99%E7%A8%8B/Data/Mnist.zip)

把下载的数据解压到一个目录中，最好是你的.py文件所在目录的.\Mnist子目录下，一共8个文件：
- Mnist-10-train-images.dat，0~9训练样本集
- Mnist-10-train-labels.dat，0~9训练标签集
- Mnist-10-test-images.dat，0~9测试样本集
- Mnist-10-test-labels.dat，0~9测试标签集
- Mnist-2-train-images.dat，0~1训练标签集
- Mnist-2-train-labels.dat，0~1训练标签集
- Mnist-2-test-images.dat，0~1测试样本集
- Mnist-2-test-labels.dat，0~1测试标签集

数据格式和原网站上的一致。可以用0~1样本先试验一下，因为样本量小，训练时间会很短。


# 图片数据归一化

在第5章中，我们学习了数据归一化，下面这段代码是第5章中使用的数据归一化方法：

```Python
def NormalizeData(X):
    X_NEW = np.zeros(X.shape)
    # get number of features
    n = X.shape[0]
    for i in range(n):
        x_row = X[i,:]
        x_max = np.max(x_row)
        x_min = np.min(x_row)
        if x_max != x_min:
            x_new = (x_row - x_min)/(x_max-x_min)
            X_NEW[i,:] = x_new
    return X_NEW
```

下面这段代码是第本章中使用的数据归一化方法：
```Python
    def __NormalizeData(self, XRawData):
        X_NEW = np.zeros(XRawData.shape)
        x_max = np.max(XRawData)
        x_min = np.min(XRawData)
        X_NEW = (XRawData - x_min)/(x_max-x_min)
        return X_NEW
```

我们使用了不一样的归一化数据处理方法，这是为什么呢？

|样本序号|1|2|3|4|...|60000|
|---|---|----|---|--|--|--|
|点1|0|0|0|0|...|0|
|点2|0|0|12|0|...|59|
|点3|0|0|56|253|...|98|
|点m|0|23|148|0|...|0|
|点784|0|0|0|0|...|0|

也就是说，数据虽然分成多个特征值（行），但是每个特征的取值范围实际上都是[0,255]。假设有这样一种情况：

|样本序号|1|2|3|4|...|60000|
|---|---|----|---|--|--|--|
|点1|0|3|0|1|...|0|
|点2|0|0|255|0|...|59|

假设第一行数据中的最大值为3，第二行数据中的最大值为255，如果逐行归一化的话，则3和255都会变成1。它们原本的含义是像素灰度，这样一来本来相差很远的两个数值，都变成1了，这不符合原始含义了。

代码位置：ch12, MnistDataReader.py
