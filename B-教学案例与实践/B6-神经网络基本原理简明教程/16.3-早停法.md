Copyright © Microsoft Corporation. All rights reserved.
  适用于[License](https://github.com/Microsoft/ai-edu/blob/master/LICENSE.md)版权许可


# 早停法 Early Stopping

## 想法的由来

从下面的图来看，如果我们在第200次迭代时，就停止训练，就应该是验证集的红色曲线的最佳取值位置了，因为此时损失值最小，而准确度值最大。

<img src=".\Images\16\overfit_result.png">

这种做法很符合直观感受，因为准确度都不再提高了，损失值反而上升了，再继续训练也是无益的，只会浪费训练的时间。那么该做法的一个重点便是怎样才认为validation accurary不再提高了呢？并不是说validation 准确度一降下来便认为不再提高了，因为可能经过这个Epoch后，准确度降低了，但是随后的Epoch又让准确度又上去了，所以不能根据一两次的连续降低就判断不再提高。

对模型进行训练的过程即是对模型的参数进行学习更新的过程，这个参数学习的过程往往会用到一些迭代方法，如梯度下降（Gradient descent）学习算法。Early stopping便是一种迭代次数截断的方法来防止过拟合的方法，即在模型对训练数据集迭代收敛之前停止迭代来防止过拟合。

## 算法

一般的做法是，在训练的过程中，记录到目前为止最好的validation 准确度，当连续N次Epoch（比如N=10或者更多次）没达到最佳准确度时，则可以认为准确度不再提高了。此时便可以停止迭代了（Early Stopping）。这种策略也称为“No-improvement-in-N”，N即Epoch的次数，可以根据实际情况取，如10、20、30……

算法描述如下：

> 初始化
>> 初始权重均值参数：$\theta \leftarrow \theta_0$

>> 迭代次数：$i \leftarrow 0$

>> 忍耐次数：$patience \leftarrow N$ (e.g. N=10)

>> 忍耐次数计数器：$counter \leftarrow 0$

>> 验证集损失函数值：$lastLoss \leftarrow \infty$

> $while (epoch \lt maxEpoch)$ 循环迭代训练过程
>> 正向计算，反向传播更新$\theta$

>> 迭代次数加1：$i \leftarrow i+1$

>> 计算验证集损失函数值：$newLoss \leftarrow loss$

>> $if (newLoss \lt lastLoss)$ // 新的损失值更小

>>> 忍耐次数计数器归零：$counter \leftarrow 0$

>>> 记录当前最佳权重矩阵训练参数：$\theta_{best} \leftarrow \theta$

>>> 记录当前迭代次数：$i_{best} \leftarrow i$

>>> 更新最新验证集损失函数值：$lastLoss \leftarrow newLoss$

>> $else$ // 新的损失值大于上一步的损失值
>>> 忍耐次数计数器加1：$counter \leftarrow counter+1$

>>> $if(counter \ge patience)$ 停止训练！！！

>> $end if$

> $end while$

此时，$\theta_{best}和i_{best}$就是最佳权重矩阵迭代次数。

## 要注意的问题

1. 门限值patience不能太小，比如小于5，因为很可能在5个epoch之外，损失函数值又会再次下降
2. Patience不能太大，比如大于30，因为在这30个epoch之内，由于样本数量少和数据shuffle的关系，很可能某个epoch的损失函数值会比上一次低，这样忍耐次数计数器counter就清零了，从而不能及时停止。
3. 当样本数量少时，为了获得平滑的变化曲线，可以考虑使用加权平均的方式处理当前和历史损失函数值，以避免某一次的高低带来的影响。

## 后续的步骤

在得到早停的迭代次数和权重矩阵参数后，后续有几种方法可以选择。

### 彻底停止

就是啥也不做了，最多再重复几次早停的的试验，看看是不是稳定，然后就使用$\theta_{best}$做为训练结果。

### 再次训练

记住了早停时的迭代次数，可以重新初始化权重矩阵参数，使用所有数据再次训练，不再分训练集和验证集，然后到达第一次的$i_{best}$时停止。但是由于样本多了，更新批次也会变多，所以可以比较两种策略：1) 总迭代次数epoch保持不变；2) 总更新梯度的次数保持不变。

优点：使用更多的样本可以达到更好的泛化能力。

缺点：需要重新花时间训练。

### 继续训练

得到$\theta_{best}$后，用全部训练数据（不再分训练集和验证集），在此基础上继续训练若干轮，并且继续用以前的验证集来监控损失函数值，如果能得到比以前更低的损失值，将会是比较理想的情况。

优点：可以避免重新训练的成本。

缺点：有可能不能达到目的，损失值降不到理想位置，从而不能终止训练。

## 理论基础

早停法，实际上也是一种正则化的策略，可以理解为在网络训练不断逼近最优解的过程种（实际上这个最优解是过拟合的），在梯度等高线的外围就停止了训练，所以其原理上和L2正则是一样的。

## 实现

首先，在CLossHistory类中，增加以下成员以支持早停机制：
- early_stop：True表示激活早停机制判断
- patience：忍耐次数上限，缺省值为5次
- patience_counter：忍耐次数计数器
- last_vld_loss：到目前为止最小的验证集损失值

```Python
class CLossHistory(object):
    def __init__(self, need_earlyStop = False, patience = 5):
        # loss history
        self.loss_history_train = []
        self.accuracy_history_train = []
        self.iteration_history_train = []
        self.epoch_history_train = []

        self.loss_history_val = []
        self.accuracy_history_val = []
       
        # for early stop
        self.min_loss_index = -1
        self.early_stop = need_earlyStop
        self.patience = patience
        self.patience_counter = 0
        self.last_vld_loss = float("inf")

    def Add(self, epoch, total_iteration, loss_train, accuracy_train, loss_vld, accuracy_vld):
        self.iteration_history_train.append(total_iteration)
        self.epoch_history_train.append(epoch)
        self.loss_history_train.append(loss_train)
        self.accuracy_history_train.append(accuracy_train)
        if loss_vld is not None:
            self.loss_history_val.append(loss_vld)
        if accuracy_vld is not None:
            self.accuracy_history_val.append(accuracy_vld)

        if self.early_stop:
            if loss_vld < self.last_vld_loss:
                self.patience_counter = 0
                self.last_vld_loss = loss_vld
            else:
                self.patience_counter += 1
                if self.patience_counter >= self.patience:
                    return True     # need to stop
            # end if
        return False
```
接下来在Add()函数的代码中，如果激活了early_stop机制，则：
1. 判断loss_vld是否小于last_vld_loss，如果是，清零计数器，保存最新loss值
2. 如果否，计数器加1，判断是否达到门限值，是的话返回True，否则返回False

在main过程中，设置超参时指定正则项为RegularMethod.EarlyStop，并且lambd=5 (即门限值为5)。

```Python
    params = CParameters(
        learning_rate, max_epoch, batch_size, eps,
        LossFunctionName.CrossEntropy3, 
        InitialMethod.Xavier, 
        OptimizerName.SGD,
        RegularMethod.EarlyStop, lambd=5)
```

注意，我们仍然使用和过拟合试验中一样的神经网络，宽度深度不变，只是增加了早停逻辑。

运行程序后，训练只迭代了200多次就停止了，损失值和准确度的曲线如下：

<img src=".\Images\16\early_stop.png">

从上图可以看到，早停法完全达到了我们的目的。

# 参考资料

- 《深度学习》- 伊恩·古德费洛

