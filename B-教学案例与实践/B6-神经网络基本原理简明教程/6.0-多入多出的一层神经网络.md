Copyright © Microsoft Corporation. All rights reserved.
  适用于[License](https://github.com/Microsoft/ai-edu/blob/master/LICENSE.md)版权许可
  
# 知识点

- 线性分类
- Softmax使用
- 交叉熵代价函数

# 提出问题

由于北京的特殊地理位置，政治经济文化医疗教育.......的中心，人口密集，城市拥挤，空气污染问题一直被人们所关注。下面这组数据，是不同温度、湿度下的PM2.5（可入肺颗粒物，标签为0）、PM10（可吸入颗粒物，标签为1）、TSP（总悬浮颗粒物，标签为2）在地表人类活动层的主要占比。

|样本序号|1|2|3|4|...|200|
|---|---|----|---|--|--|--|
|温度|0|13|2|24|...|8|
|湿度|55|14|46|58|...|78|
|污染物|0|2|1|2|...|0|


下图中，红点代表PM2.5，蓝点代表PM10，绿点代表TSP。

<img src=".\Images\6\data.png">

举例来说，当温度是25摄氏度，湿度是40时，处于蓝色点区域，即PM10占比较大，并不是说这个条件下污染物只有PM10。

### 问题，给定温度湿度条件下，预测当前那种污染物占主要比重？
#### 1. 温度=5.1摄氏度，湿度=12.7
#### 2. 温度=25.3摄氏度，湿度=42.1
#### 3. 温度=34.3摄氏度，湿度=82.2

你可能会觉得这个太简单了，这不是有图吗？定位坐标值后一下子就找到对应的区域了。但是我们要求你用机器学习的方法来解决这个看似简单的问题，以便将来的预测行为是快速准确的，而不是拿个尺子在图上去比划。再说了，我们用这个例子，主要是想让大家对问题和解决方法都有一个视觉上的清晰认识，而这类可以可视化的问题，在实际生产环境中并不多见，绝大多数都是属于乐山大佛——一头雾水。

## 问题分析

从图示来看，似乎在三个颜色区间之间有两个比较明显的分界线，而且是直线，即线性可分的。我们如何通过神经网络精确地找到这两条分界线呢？

- 从视觉上判断是线性可分的，所以我们使用单层神经网络即可
- 输入特征是温度和湿度，所以我们在输入层设置两个输入X1=温度值，X2=湿度值
- 最后输出的是三个分类，分别是PM2.5，PM10，TSP，所以输出层有三个神经元

# 定义神经网络结构

这个网络只有输入层和输出层，由于输入层不算在内，所以是一层网络。

<img src=".\Images\6\NN.jpg">

与前面的单层网络不同的是，本图最右侧的输出层还多出来一个Softmax分类函数，这是多分类任务中的标准配置。

## 输入层

## 权重矩阵W1/B1

W权重矩阵的尺寸，可以从后往前看，比如：输出层是3个神经元，输入层是2个特征，则W的尺寸就是3x2。

$$
W=\begin{pmatrix}
w_{11} & w_{12} \\
w_{21} & w_{22} \\
w_{31} & w_{32} 
\end{pmatrix}
$$

B的尺寸是3x1，行数永远和W一样，列数永远是1。

$$
B=\begin{pmatrix}
b_1 \\
b_2 \\
b_3 
\end{pmatrix}
$$

## 输出层

输出层三个神经元，再加上一个Softmax计算，最后有A1,A2,A3三个输出，写作：

$$
Z = \begin{pmatrix}Z1 \\ Z2 \\ Z3 \end{pmatrix},
A = \begin{pmatrix}A1 \\ A2 \\ A3 \end{pmatrix}
$$

其中，$Z=W*X+B，A = Softmax(Z)$

# 训练数据

## 下载数据
下载后拷贝到您要运行的Python文件所在的文件夹。

二分类

[点击下载训练样本数据X](https://github.com/Microsoft/ai-edu/tree/master/B-%E6%95%99%E5%AD%A6%E6%A1%88%E4%BE%8B%E4%B8%8E%E5%AE%9E%E8%B7%B5/B6-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%E7%AE%80%E6%98%8E%E6%95%99%E7%A8%8B/Data/Pollution2CategoryX.dat)

[点击下载训练标签数据Y](https://github.com/Microsoft/ai-edu/tree/master/B-%E6%95%99%E5%AD%A6%E6%A1%88%E4%BE%8B%E4%B8%8E%E5%AE%9E%E8%B7%B5/B6-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%E7%AE%80%E6%98%8E%E6%95%99%E7%A8%8B/Data/Pollution2CategoryY.dat)


三分类

[点击下载训练样本数据X](https://github.com/Microsoft/ai-edu/tree/master/B-%E6%95%99%E5%AD%A6%E6%A1%88%E4%BE%8B%E4%B8%8E%E5%AE%9E%E8%B7%B5/B6-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%E7%AE%80%E6%98%8E%E6%95%99%E7%A8%8B/Data/Pollution3CategoryX.dat)

[点击下载训练标签数据Y](https://github.com/Microsoft/ai-edu/tree/master/B-%E6%95%99%E5%AD%A6%E6%A1%88%E4%BE%8B%E4%B8%8E%E5%AE%9E%E8%B7%B5/B6-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%E7%AE%80%E6%98%8E%E6%95%99%E7%A8%8B/Data/Pollution3CategoryY.dat)


## 样本特征值

样本数据集中一共有200个数据，每个数据有两个特征，温度和湿度。所以定义矩阵如下：

$$
X_m = 
\begin{pmatrix}
x_1 \\ x_2
\end{pmatrix}
$$

$X_m$表示第m个样本值，$x_{m,n}$表示第m个样本的第n个特征值。
样本数据集中一共有200个数据，每个数据有两个特征：温度和湿度。所以定义矩阵如下：
$$
X = 
\begin{pmatrix}
X_1 & X_2 \dots X_{200}
\end{pmatrix}=
\begin{pmatrix}
x_{1,1} & x_{2,1} \dots x_{200,1} \\
\\
x_{1,2} & x_{2,2} \dots x_{200,2} \\
 \end{pmatrix}
$$

## 样本标签数据
一般来说，在标记样本时，我们会用0，1，2这样的标记，来指明是哪一类。在有Softmax的多分类计算时，我们用下面这种等价的方式，俗称One-Hot，就是在一个向量中只有一个数据是1，其它都是0。
$$
Y = 
\begin{pmatrix}
Y_1 & Y_2 \dots Y_m
\end{pmatrix}=
\begin{pmatrix}
y_{1,1} & y_{2,1} \dots y_{200,1} \\
\\
y_{1,2} & y_{2,2} \dots y_{200,2} \\
\\
y_{1,3} & y_{2,3} \dots y_{200,3}
\end{pmatrix}=
\begin{pmatrix}
1 & 0 \dots 0 \\
0 & 0 \dots 1 \\
0 & 1 \dots 0
\end{pmatrix}
$$

标签数据对应到每个样本数据上，列对齐，只有(1,0,0)，(0,1,0)，(0,0,1)三种组合，分别表示第一类(PM2.5)、第二类(PM10)和第三类(TSP)污染物占主要比重。当然我们不能排除某一时刻既有PM2.5又有PM10的情况，但两者总有一个占比重大，一个占比重小，所以就指定占比大的那个为1，其余两个为0。

## 加载数据
```Python
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path

x_data_name = "PollutionCategoryXData.dat"
y_data_name = "PollutionCategoryYData.dat"

def LoadData():
    Xfile = Path("WeatherXData.dat")
    Yfile = Path("WeatherYData.dat")
    if Xfile.exists() & Yfile.exists():
        XData = np.load(Xfile)
        YData = np.load(Yfile)
        return XData,YData
    
    return None,None
```

# 前向计算

```Python
def ForwardCalculation(W, X, B):
    Z = np.dot(W,X) + B
    return Z
```

# 分类函数

```Python
def Softmax(Z):
    shift_z = Z - np.max(Z)
    exp_z = np.exp(shift_z)
    A = exp_z / np.sum(exp_z, axis=0)
    return A
```

# 损失函数
```Python
def CheckLoss(W, B, X, Y, count, prev_loss):
    Z = ForwardCalculation(W,X,B)
    A = Softmax(Z)
    # binary classification
    #p1 = (1-Y) * np.log(1-A)  
    p2 = Y * np.log(A)
    # binary classification
    #LOSS = np.sum(-(p1 + p2))
    # multiple classification
    LOSS = np.sum(-p2)
    loss = LOSS / count
    diff_loss = abs(loss - prev_loss)
    return loss, diff_loss
```

# 反向传播
```Python
def BackPropagation(Xm, Ym, A):
    dZ = A - Ym
    dB = dZ
    dW = np.dot(dZ, Xm.T)
    return dW, dB

def UpdateWeights(W, B, dW, dB, eta):
    W = W - eta*dW
    B = B - eta*dB
    return W,B
```
# 数据归一化

```Python
def NormalizeByData(X):
    X_new = np.zeros(X.shape)
    n = X.shape[0]
    x_range = np.zeros((1,n))
    x_min = np.zeros((1,n))
    for i in range(n):
        x = X[i,:]
        max_value = np.max(x)
        min_value = np.min(x)
        x_min[0,i] = min_value
        x_range[0,i] = max_value - min_value
        x_new = (x - x_min[0,i])/(x_range[0,i])
        X_new[i,:] = x_new
    return X_new, x_range, x_min

    # normalize data by specified range and min_value
def NormalizeByRange(X, x_range, x_min):
    X_new = np.zeros(X.shape)
    n = X.shape[0]
    for i in range(n):
        x = X[i,:]
        x_new = (x-x_min[0,i])/x_range[0,i]
        X_new[i,:] = x_new
    return X_new
```

# 初始化
```Python
def InitialWeights(num_category, num_features, flag):
    if flag == 'zero':
        W = np.zeros((num_category,num_features))
        B = np.zeros((num_category,1))
    elif flag == 'random':
        W = np.random.random((num_category,num_features))
        B = np.random.random((num_category,1))
    return W, B
```

# 可视化训练结果
```Python
def ShowResult(X,Y,W,B,rangeX,eta,iteration,eps):
    for i in range(X.shape[1]):
        if Y[0,i] == 0 and Y[1,i]==0 and Y[2,i]==1:
            plt.scatter(X[0,i], X[1,i], c='r')
        elif Y[0,i] == 0 and Y[1,i]==1 and Y[2,i]==0:
            plt.scatter(X[0,i], X[1,i], c='b')
        else:
            plt.scatter(X[0,i], X[1,i], c='g')
   
    b12 = (B[1,0] - B[0,0])/(W[0,1] - W[1,1])
    w12 = (W[1,0] - W[0,0])/(W[0,1] - W[1,1])

    b23 = (B[2,0] - B[1,0])/(W[1,1] - W[2,1])
    w23 = (W[2,0] - W[1,0])/(W[1,1] - W[2,1])

    x = np.linspace(0,rangeX,10)
    y = w12 * x + b12
    plt.plot(x,y)

    x = np.linspace(0,rangeX,10)
    y = w23 * x + b23
    plt.plot(x,y)

    title = str.format("eta:{0}, iteration:{1}, eps:{2}", eta, iteration, eps)
    plt.title(title)
    
    plt.xlabel("Temperature")
    plt.ylabel("Humidity")
    plt.show()
```
# 推理预测

大家还记得第5章时，我们还原W的过程吧？在本章中，那个方法将不会再有效，因为本章的问题的W是一个3x2的矩阵，每一列有三个数字，无法确定如何还原到真实的W值。所以，我们使用标准的推理方法，即，把要推理的输入值先做与训练时相同的归一化，再放入模型中进行计算。

```Python
def Inference(W,B,xt,X_range,X_min):
    xt_normalized = NormalizeByRange(xt, X_range, X_min)
    Z = ForwardCalculation(W,xt_normalized,B)
    A = Softmax(Z)
    r = np.argmax(A)
    return r
```
最后一个函数np.argmax的作用是比较A里面的几个数据的值，返回最大的那个数据的行数或者列数，0-based。比如A=(1.02,-3,2.2)时，会返回2，因为2.2最大。

# 主程序
```Python
XData, Y = LoadData()
X, X_range, X_min = NormalizeByData(XData)
num_features = X.shape[0]
num_samples = X.shape[1]
num_category = Y.shape[0]
prev_loss, loss, diff_loss = 0,0,0
eps=1e-10
W, B = InitialWeights(num_category, num_features, 'zero')
eta = 0.1
max_iteration = 1000

for iteration in range(max_iteration):
    for i in range(num_samples):
        Xm = X[:,i].reshape(num_features,1)
        Ym = Y[:,i].reshape(num_category,1)
        Z = ForwardCalculation(W,Xm,B)
        A = Softmax(Z)
        dw,db = BackPropagation(Xm, Ym, A)
        W,B = UpdateWeights(W, B, dw, db, eta)
        loss, diff_loss = CheckLoss(W,B,X,Y,num_samples,prev_loss)
        if i%10==0:
            print(iteration,i,loss,diff_loss)
        # condition 1 to stop
        if diff_loss < eps:
            print(loss, diff_loss)
            break
        prev_loss = loss

    if diff_loss < eps:
        break

show_result(X,Y,W,B,np.max(X[0,:]),eta,iteration)
print(W)
print(B)

xt = np.array([5.1,12.7]).reshape(2,1)
result = Inference(W,B,xt,X_range,X_min)
print(result)

xt = np.array([25.3,42.1]).reshape(2,1)
result = Inference(W,B,xt,X_range,X_min)
print(result)

xt = np.array([34.3,82.2]).reshape(2,1)
result = Inference(W,B,xt,X_range,X_min)
print(result)
```

# 运行结果

<img src=".\Images\6\eps1e-10.png">

```
W:
[[  0.07915207 -22.7280822 ]
 [  3.39770519   0.20577086]
 [ -3.47685725  22.52231134]]
B:
[[ 10.87780651]
 [  1.30040341]
 [-12.17820992]]
0
1
2
```
1. 温度=5.1摄氏度，湿度=12.7，r=0，第一种污染物占比最大
2. 温度=25.3摄氏度，湿度=42.1，r=1，第二种污染物占比最大
3. 温度=34.3摄氏度，湿度=82.2，r=2，第三种污染物占比最大

从视觉上看，分界线也基本把三段数据划分成了不同的区。
