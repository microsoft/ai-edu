Copyright © Microsoft Corporation. All rights reserved.
  适用于[License](https://github.com/Microsoft/ai-edu/blob/master/LICENSE.md)版权许可
  
# 二分类问题

1. PM2.5（可入肺颗粒物，标签为1，蓝色点）
2. PM10（可吸入颗粒物，标签为2，绿色点）

|样本序号|1|2|3|4|...|119|
|---|---|----|---|--|--|--|
|温度(摄氏度)|23.77|8.16|8.09|25.15|...|36.48|
|海拔(米)|71.86|59.21|75.51|16.87|...|14.28|
|污染物种类|2|2|2|1|...|1|

<img src=".\Images\6\BinaryClassifierData.png">


## 问题分析

从图示来看，在两个颜色区间之间有两个比较明显的空白区域，即线性可分的。我们如何通过神经网络精确地找到这条分界线呢？

- 从视觉上判断是线性可分的，所以我们使用单层神经网络即可
- 输入特征是温度和湿度，所以我们在输入层设置两个输入X1=温度值，X2=湿度值
- 最后输出的是两个分类，分别是PM2.5，PM10，可以看成非0即1的二分类问题，所以我们用一个输出就可以了

那么最后我们只需要一个二入一出的神经元就可以搞定。

在输出层使用单个神经元输出，使用Sigmoid激活函数和下面这种交叉熵损失函数：
$$
Z = W * X + B \tag{矩阵计算}
$$

$$
A=Sigmoid(Z) \tag{Logistic激活函数用于二分类}
$$

$$
Loss = -[Y * lnA+(1-Y) * ln(1-A)] \tag{二分类交叉熵函数}
$$

|<img src=".\Images\1\NeuranCell.png" width="400"/>|<img src=".\Images\1\activation.png" width="400"/>|
|---|---|

分类的方式是，可以指定当A > 0.5时是正例，A <= 0.5时就是反例。或者根据实际情况指定别的阈值比如0.3，0.8等等。

此时反向传播公式推导结果是：

$$
\frac{\partial{Loss}}{\partial{A}}=-[\frac{Y}{A}+\frac{1-Y}{1-A}*(-1)]=\frac{A-Y}{A(1-A)} \tag{交叉熵函数求导}
$$
$$
\frac{\partial{A}}{\partial{Z}}=A(1-A) \tag{Sigmoid激活函数求导}
$$
$$
\frac{\partial{Z}}{\partial{W}}=X^T , \frac{\partial{Z}}{\partial{B}}=1 \tag{矩阵运算求导}
$$

所以：

$$
\frac{\partial{Loss}}{\partial{W}} = \frac{\partial{Loss}}{\partial{A}} * \frac{\partial{A}}{\partial{Z}} * \frac{\partial{Z}}{\partial{W}} \\
=\frac{A-Y}{A(1-A)} * A(1-A) * X^T \\
=(A-Y) * X^T \tag{W的梯度}
$$

$$
\frac{\partial{Loss}}{\partial{B}}=\frac{\partial{Loss}}{\partial{A}} * \frac{\partial{A}}{\partial{Z}} * \frac{\partial{Z}}{\partial{B}} \\
=\frac{A-Y}{A(1-A)} * A(1-A) \\
=A-Y \tag{B的梯度}
$$


# 定义神经网络结构

这个网络只有输入层和输出层，由于输入层不算在内，所以是一层网络。

<img src=".\Images\6\BinaryClassifierNN.png">

与前面的单层网络不同的是，本图最右侧的输出层还多出来一个Softmax分类函数，这是多分类任务中的标准配置。

## 输入层

输入温度(x1)和高度(x2)两个特征：

$$
X=\begin{pmatrix}
x_1 \\ x_2
\end{pmatrix}
$$


## 权重矩阵W1/B1

输入层是2个特征，则W的尺寸就是1x2：

$$
W=\begin{pmatrix}
w_1 & w_2
\end{pmatrix}
$$

B的尺寸是1x1，行数永远和W一样，列数永远是1。

$$
B=\begin{pmatrix}
b_1
\end{pmatrix}
$$

## 输出层

$$Z=W \cdot X+B$$$$
A = Sigmoid(Z)$$

# 训练数据

## 下载数据
下载后拷贝到您要运行的Python文件所在的文件夹。

[点击下载训练样本数据X](https://github.com/Microsoft/ai-edu/tree/master/B-%E6%95%99%E5%AD%A6%E6%A1%88%E4%BE%8B%E4%B8%8E%E5%AE%9E%E8%B7%B5/B6-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%E7%AE%80%E6%98%8E%E6%95%99%E7%A8%8B/Data/Pollution2CategoryX.dat)

[点击下载训练标签数据Y](https://github.com/Microsoft/ai-edu/tree/master/B-%E6%95%99%E5%AD%A6%E6%A1%88%E4%BE%8B%E4%B8%8E%E5%AE%9E%E8%B7%B5/B6-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%E7%AE%80%E6%98%8E%E6%95%99%E7%A8%8B/Data/Pollution2CategoryY.dat)

## 样本特征值

样本数据集中一共有200个数据，每个数据有两个特征，温度和湿度。所以定义矩阵如下：

$$
X_m = 
\begin{pmatrix}
x_1 \\ x_2
\end{pmatrix}
$$

$X_m$表示第m个样本值，$x_{m,n}$表示第m个样本的第n个特征值。
样本数据集中一共有200个数据，每个数据有两个特征：温度和湿度。所以定义矩阵如下：
$$
X = 
\begin{pmatrix}
X_1 & X_2 \dots X_{200}
\end{pmatrix}=
\begin{pmatrix}
x_{1,1} & x_{2,1} \dots x_{200,1} \\
\\
x_{1,2} & x_{2,2} \dots x_{200,2} \\
 \end{pmatrix}
$$

## 样本标签数据
一般来说，在标记样本时，我们会用0，1，2这样的标记，来指明是哪一类。在有Softmax的多分类计算时，我们用下面这种等价的方式，俗称One-Hot，就是在一个向量中只有一个数据是1，其它都是0。
$$
Y = 
\begin{pmatrix}
Y_1 & Y_2 \dots Y_m
\end{pmatrix}=
\begin{pmatrix}
y_{1,1} & y_{2,1} \dots y_{200,1} \\
\\
y_{1,2} & y_{2,2} \dots y_{200,2} \\
\\
y_{1,3} & y_{2,3} \dots y_{200,3}
\end{pmatrix}=
\begin{pmatrix}
1 & 0 \dots 0 \\
0 & 0 \dots 1 \\
0 & 1 \dots 0
\end{pmatrix}
$$

标签数据对应到每个样本数据上，列对齐，只有(1,0,0)，(0,1,0)，(0,0,1)三种组合，分别表示第一类(PM2.5)、第二类(PM10)和第三类(TSP)污染物占主要比重。当然我们不能排除某一时刻既有PM2.5又有PM10的情况，但两者总有一个占比重大，一个占比重小，所以就指定占比大的那个为1，其余两个为0。

## 加载数据
```Python
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path

x_data_name = "PollutionCategoryXData.dat"
y_data_name = "PollutionCategoryYData.dat"

```

# 前向计算

```Python
def ForwardCalculation(W, X, B):
    Z = np.dot(W,X) + B
    return Z
```

# 分类函数

```Python
def Softmax(Z):
    shift_z = Z - np.max(Z)
    exp_z = np.exp(shift_z)
    A = exp_z / np.sum(exp_z, axis=0)
    return A
```

# 损失函数
```Python
def CheckLoss(W, B, X, Y, count, prev_loss):
    Z = ForwardCalculation(W,X,B)
    A = Softmax(Z)
    # binary classification
    #p1 = (1-Y) * np.log(1-A)  
    p2 = Y * np.log(A)
    # binary classification
    #LOSS = np.sum(-(p1 + p2))
    # multiple classification
    LOSS = np.sum(-p2)
    loss = LOSS / count
    diff_loss = abs(loss - prev_loss)
    return loss, diff_loss
```

# 可视化训练结果
```Python
def ShowResult(X,Y,W,B,rangeX,eta,iteration,eps):
    for i in range(X.shape[1]):
        if Y[0,i] == 0 and Y[1,i]==0 and Y[2,i]==1:
            plt.scatter(X[0,i], X[1,i], c='r')
        elif Y[0,i] == 0 and Y[1,i]==1 and Y[2,i]==0:
            plt.scatter(X[0,i], X[1,i], c='b')
        else:
            plt.scatter(X[0,i], X[1,i], c='g')
   
    b12 = (B[1,0] - B[0,0])/(W[0,1] - W[1,1])
    w12 = (W[1,0] - W[0,0])/(W[0,1] - W[1,1])

    b23 = (B[2,0] - B[1,0])/(W[1,1] - W[2,1])
    w23 = (W[2,0] - W[1,0])/(W[1,1] - W[2,1])

    x = np.linspace(0,rangeX,10)
    y = w12 * x + b12
    plt.plot(x,y)

    x = np.linspace(0,rangeX,10)
    y = w23 * x + b23
    plt.plot(x,y)

    title = str.format("eta:{0}, iteration:{1}, eps:{2}", eta, iteration, eps)
    plt.title(title)
    
    plt.xlabel("Temperature")
    plt.ylabel("Humidity")
    plt.show()
```
# 推理预测

大家还记得第5章时，我们还原W的过程吧？在本章中，那个方法将不会再有效，因为本章的问题的W是一个3x2的矩阵，每一列有三个数字，无法确定如何还原到真实的W值。所以，我们使用标准的推理方法，即，把要推理的输入值先做与训练时相同的归一化，再放入模型中进行计算。

```Python
def Inference(W,B,xt,X_range,X_min):
    xt_normalized = NormalizeByRange(xt, X_range, X_min)
    Z = ForwardCalculation(W,xt_normalized,B)
    A = Softmax(Z)
    r = np.argmax(A)
    return r
```
最后一个函数np.argmax的作用是比较A里面的几个数据的值，返回最大的那个数据的行数或者列数，0-based。比如A=(1.02,-3,2.2)时，会返回2，因为2.2最大。

# 主程序
```Python
XData, Y = LoadData()
X, X_range, X_min = NormalizeByData(XData)
num_features = X.shape[0]
num_samples = X.shape[1]
num_category = Y.shape[0]
prev_loss, loss, diff_loss = 0,0,0
eps=1e-10
W, B = InitialWeights(num_category, num_features, 'zero')
eta = 0.1
max_iteration = 1000

for iteration in range(max_iteration):
    for i in range(num_samples):
        Xm = X[:,i].reshape(num_features,1)
        Ym = Y[:,i].reshape(num_category,1)
        Z = ForwardCalculation(W,Xm,B)
        A = Softmax(Z)
        dw,db = BackPropagation(Xm, Ym, A)
        W,B = UpdateWeights(W, B, dw, db, eta)
        loss, diff_loss = CheckLoss(W,B,X,Y,num_samples,prev_loss)
        if i%10==0:
            print(iteration,i,loss,diff_loss)
        # condition 1 to stop
        if diff_loss < eps:
            print(loss, diff_loss)
            break
        prev_loss = loss

    if diff_loss < eps:
        break

show_result(X,Y,W,B,np.max(X[0,:]),eta,iteration)
print(W)
print(B)

xt = np.array([5.1,12.7]).reshape(2,1)
result = Inference(W,B,xt,X_range,X_min)
print(result)

xt = np.array([25.3,42.1]).reshape(2,1)
result = Inference(W,B,xt,X_range,X_min)
print(result)

xt = np.array([34.3,82.2]).reshape(2,1)
result = Inference(W,B,xt,X_range,X_min)
print(result)
```

# 运行结果

<img src=".\Images\6\BinaryClassifierResult.png">

```
W:
[[  0.07915207 -22.7280822 ]
 [  3.39770519   0.20577086]
 [ -3.47685725  22.52231134]]
B:
[[ 10.87780651]
 [  1.30040341]
 [-12.17820992]]
0
1
2
```
1. 温度=5.1摄氏度，湿度=12.7，r=0，第一种污染物占比最大
2. 温度=25.3摄氏度，湿度=42.1，r=1，第二种污染物占比最大
3. 温度=34.3摄氏度，湿度=82.2，r=2，第三种污染物占比最大

从视觉上看，分界线也基本把三段数据划分成了不同的区。
