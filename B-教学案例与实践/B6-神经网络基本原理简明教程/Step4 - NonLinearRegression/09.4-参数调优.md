Copyright © Microsoft Corporation. All rights reserved.
  适用于[License](https://github.com/Microsoft/ai-edu/blob/master/LICENSE.md)版权许可

# 可调的参数

我们使用如下参数做第一次的训练：

|参数|缺省值|是否可调|注释|
|---|---|---|---|
|输入层神经元数|1|No|
|隐层神经元数|4|Yes|影响迭代次数|
|输出层神经元数|1|No|
|学习率|0.1|Yes|影响迭代次数|
|批样本量|10|Yes|影响迭代次数|
|最大epoch|30000|Yes|影响终止条件,建议不改动|
|损失门限值|0.001|Yes|影响终止条件,建议不改动|
|损失函数|MSE|No|
|参数初始化方法|Xavier|Yes|参看10.1节

木头：买嘎哒！怎么这么多参数！

铁柱：如果使用者不了解神经网络中的基本原理，那么所谓“调参”就是摸着石头过河了。今天咱们可以试着改变几个参数，来看看训练结果。

## 前提

初始化是神经网络训练非常重要的环节之一，不同的初始化方法，甚至是相同的方法但不同的随机值，都会给结果带来或多或少的影响。

在后面的几组比较中，都是用Xavier方法初始化的。另外，两次使用Xavier初始化，也会得到不同的结果，为了避免这个随机性，我们在代码Level0_TwoLayerFittingNet.py中，使用了一个小技巧，调用下面这个函数：

```Python
    def InitializeWeights(self, create_new = False):
        self.__GenerateWeightsArrayFileName()
        if create_new:
            self.__CreateNew()
        else:
            self.__LoadExistingParameters()
        # end if
        self.dW = np.zeros(self.W.shape)
        self.dB = np.zeros(self.B.shape)

```

第一次调用时，会得到一个随机初始化矩阵。以后再次调用时，如果参数值为False，只要隐层神经元数量不变并且初始化方法不变，就会用第一次的初始化结果，否则后面的各种参数调整的结果就没有可比性了。

# 学习率的调整

我们固定其它参数，改变学习率，下面是损失函数值的曲线：

<img src="..\Images\9\eta.png">

|学习率|迭代次数|说明|
|----|----|----|
|0.1|9540|学习率小，收敛最慢|
|0.3|4360|学习率增大，收敛增快|
|0.5|2780|最快|
|0.7|3040|学习率进一步增大，但收敛不一定快|

对于拟合曲线这个特定问题，较大的学习率可以带来很快的收敛速度，但是有两点：
- 但并不是对所有问题都这样，有的问题可能需要0.001或者更小的学习率
- 学习率大时，开始时收敛快，但是到了后来有可能会错失最佳解

# 批大小的调整

我们固定其它参数，调整批大小，比较结果如下：

<img src="..\Images\9\batchsize.png">

|批大小|迭代次数|说明|
|----|----|----|
|1|4680|批数据量小到1，收敛慢|
|5|2540|批数据量增大，收敛最快|
|10|2780|批数据量进一步增大，收敛变慢|
|20|4670|批数据量太大，反而会降低收敛速度|

合适的批样本量会带来较快的收敛，前提是我们固定了学习率。如果想用较大的批数据，底层数据库计算的速度较快，但是需要同时调整学习率，才会相应地提高收敛速度。

这个结论的前提是我们用了0.5的学习率，如果用0.1的话，将会得到不同结论。

# 隐层神经元数量的调整

这次我们调整隐层神经元的数量：

<img src="..\Images\9\neuron_number.png">

|隐层神经元数量|迭代次数|说明|
|---|---|---|
|2|9990|神经元数量少，拟合能力低|
|4|2540|神经元数量对于这个问题最合适|
|6|4200|神经元多了不一定能帮上忙，还有可能帮倒忙|
|8|3470|再多一些神经元会有一些用处|

对于这个特定问题，隐层神经元个数为4时，收敛速度最快。

# 课后作业

使用下列参数设置，找到批大小和学习率的关系：

- 隐层神经元：4
- 初始化：Xavier
- 批大小选择：1，5，10，15，20，25，30
- 学习率选择：0.1，0.3，0.5，0.7

得到下表：

|批大小|1|5|10|15|20|
|---|---|---|---|---|---|
|0.1|epoch=?|epoch=?|epoch=?|epoch=?|epoch=?|
|0.3|epoch=?|epoch=?|epoch=?|epoch=?|epoch=?|
|0.5|epoch=?|epoch=?|epoch=?|epoch=?|epoch=?|
|0.7|epoch=?|epoch=?|epoch=?|epoch=?|epoch=?|
|0.9|epoch=?|epoch=?|epoch=?|epoch=?|epoch=?|

从而得到批大小与学习率的最佳组合。

代码位置：ch09, Level2