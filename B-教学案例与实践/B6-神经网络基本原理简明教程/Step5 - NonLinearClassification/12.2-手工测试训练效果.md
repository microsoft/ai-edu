Copyright © Microsoft Corporation. All rights reserved.
  适用于[License](https://github.com/Microsoft/ai-edu/blob/master/LICENSE.md)版权许可

## 12.2 手工测试训练效果

需要安装pillow图像工具包：pip install pillow

## 保存训练结果

这一节我们将学习如何用Python提供交互式界面来实现一个能手写输入的程序，从而验证MNIST的训练结果。

神经网络的训练结果，是那些权重矩阵。在三层神经网络的例子中，我们在训练完成之后，有一段代码如下：

```Python
def SaveResult(dict_param):
    np.save("Level3_w1.npy", dict_param["W1"])
    np.save("Level3_b1.npy", dict_param["B1"])
    np.save("Level3_w2.npy", dict_param["W2"])
    np.save("Level3_b2.npy", dict_param["B2"])
    np.save("Level3_w3.npy", dict_param["W3"])
    np.save("Level3_b3.npy", dict_param["B3"])
```

它的功能是把训练好的网络各层的权重和偏移参数保存到文件中，这样我们以后可以在使用这个网络推理时，方便地把这些参数重新加载到网络中，而不需要重新训练。前提是训练和推理的网络结构要一摸一样。而在训练过程中出现的各种参数，是不会出现在最终结果中的。

## 推理的过程

推理，Inference，就是在实际中应用的过程，即把网络要求的数据格式输入后，它可以快速计算，吐出一个结果，告诉用户分类或者拟合的结果。实际的推理过程，其实就是训练过程中的前向计算函数：

```Python
def forward3(X, dict_Param):
    W1 = dict_Param["W1"]
    B1 = dict_Param["B1"]
    W2 = dict_Param["W2"]
    B2 = dict_Param["B2"]
    W3 = dict_Param["W3"]
    B3 = dict_Param["B3"]
    
    Z1 = np.dot(W1,X) + B1
    A1 = Sigmoid(Z1)

    Z2 = np.dot(W2,A1) + B2
    A2 = Tanh(Z2)

    Z3 = np.dot(W3,A2) + B3
    A3 = Softmax(Z3)
    
    dict_Cache = {"Z1": Z1, "A1": A1, "Z2": Z2, "A2": A2, "Z3": Z3, "A3": A3, "Output": A3}
    return dict_Cache
```

因为在训练过程中，需要一些计算的中间结果，所以在上述代码返回的dict_Cache中包含了一堆东西。而在实际的推理过程中，我们只需要关心A3，即Output，就可以了。

下图就是上述代码对应的三层神经网络的前向计算图：

<img src='../Images/12/forward3.png'/>

假设我们预先训练好了这个网络，并且保存了训练结果，在推理时只需要加载训练结果：

```Python
def LoadNet():
    W1 = np.load("Level3_w1.npy")
    B1 = np.load("Level3_b1.npy")
    W2 = np.load("Level3_w2.npy")
    B2 = np.load("Level3_b2.npy")
    W3 = np.load("Level3_w3.npy")
    B3 = np.load("Level3_b3.npy")
    dict_param = {"W1":W1, "B1":B1, "W2":W2, "B2":B2, "W3":W3, "B3":B3}
    return dict_param
  ```

  加载方法返回一个字典，正好是前向计算函数所需要的第二个参数。而第一个参数X，需要从实际应用中获取，输入网络后，就会沿着箭头方向计算，最后得到A3。这个推理过程一般都是毫秒级的，但是如果有大量并发数据出现，最好还是把它们组成矩阵形式，一次性地输入到X中，会比循环调用推理过程高效很多。

## 搭建推理应用

在Python中，有一些图形界面包可以搭建复杂的交互式应用。我们需要实现的步骤有：

1. 重现神经网络结构，加载权重和偏移数据
2. 显示界面，让用户可以用鼠标或者手指（触摸屏）写一个数字
3. 写好一个数字后，收集数据，转换数据，并触发推理过程
4. 得到推理结果
5. 清除界面，做下一次测试

如何加载数据，我们上面以及说过了。下一步是用matplotlib提供的功能显示一个绘图面板：

<img src='../Images/12/inference1.png'/>

这是一个方形的空面板，坐标为[0,1]，但实际上它的初始尺寸是640x480，在使用之前，我们先把它拉成一个正方形（宽高大致近似即可），因为在训练时，我们使用的训练集是28x28的正方形，所以要求推理用的数据也是正方形的。

然后需要在这个面板上注册事件，以响应鼠标和键盘输入：

```Python
    # 加载权重和偏移数据
    dict_param = LoadNet()
    # 注册事件
    fig, ax = plt.subplots()
    # 键盘事件
    fig.canvas.mpl_connect('key_press_event', on_key_press)
    # 鼠标释放
    fig.canvas.mpl_connect('button_release_event', on_mouse_release)
    # 鼠标按下
    fig.canvas.mpl_connect('button_press_event', on_mouse_press)
    # 鼠标移动
    fig.canvas.mpl_connect('motion_notify_event', on_mouse_move)
    # 设置固定的绘图尺寸
    plt.axis([0,1,0,1])
    plt.show()
```
事件响应逻辑：

- 在鼠标按下事件中，启动绘图功能
- 在鼠标移动事件中，检查如果绘图功能开启，就在面板上显示鼠标轨迹
- 在鼠标释放事件中，关闭绘图功能
- 在键盘事件中，如果收到回车键，就触发推理过程；如果收到回退键，就清空画板

## 交互过程

在面板上写个"2"，不要担心，那些毛刺并不会影响识别结果，但是注意要写大一些，充满画板：

<img src='../Images/12/inference2.png'/>

此时会看到左侧console窗口中会显示一些辅助信息，如鼠标按下和释放的坐标。写完后，按回车键，触发数据处理和推理过程：

<img src='../Images/12/inference3.png'/>

数据处理过程：

1. 应用程序会先把绘图区域保存为一个文件
2. 然后再把此文件读入内存，转换成灰度图
3. 缩放尺寸到28x28（和训练数据一致）
4. 用255减去所有像素值，得到黑底色白前景色的数据（和训练数据一致）
5. 归一化到[0,1]（和训练数据一致）
6. 变成784x1的数组，调用前向计算方法
7. 得到Output后，做一个argmax，取到最终结果

A3的结果如下，经过sofmax计算后，“2”的概率为0.74，argmax方法会把0.74在向量中的位置2返回：

```
[[1.30227675e-05]
 [2.37117962e-01]
 [7.40282026e-01]
 [5.33239953e-04]
 [1.10064252e-06]
 [1.42939242e-04]
 [1.00293210e-03]
 [1.07402351e-03]
 [1.98273955e-02]
 [5.35748168e-06]]

------recognize result is: {0} ----- 2
```

画板中显示的图片是经过一些列数据处理后的图片（忽略它的彩色，那是matplotlib的装饰色），可以看到和原始图片的差别还是比较大的，尤其是经过缩小处理后，像素点的损失信息很多，这就要求我们在绘图时，要使用足够宽的笔迹，比如在此例中，我们使用了30像素的宽度。

代码位置：ch12, Level5

**课后作业**

修改Level3中的超参，训练MNIST数据集，令测试结果的准确度大于97%。

可以修改的参数有：
- 学习率
- 隐层1的神经元数
- 隐层2的神经元数
- 最大epoch次数
- 批大小
- 初始化权重的方法
- 