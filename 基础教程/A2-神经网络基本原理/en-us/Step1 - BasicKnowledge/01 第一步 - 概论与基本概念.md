<!--Copyright © Microsoft Corporation. All rights reserved.
  适用于[License](https://github.com/Microsoft/ai-edu/blob/master/LICENSE.md)版权许可-->

# 第一步  概论与基本概念

## 摘要

在这一步中，我们将针对零基础的初学者们，用通俗易懂的语言，讲述神经网络的基本概念。

在概论与基本概念中，首先对人工智能的发展简史、定义、以及科学范式的演化进行介绍，并列举了一些有趣的实例，让大家对人工智能的世界观方法论形成一个基本的认识。

然后讲解一下神经网络基本的训练和工作原理，因为基本上各种教程里都没有提到这一点，以至于笔者在刚开始学习神经网络时一头雾水，不得要领，不知从何处开始下手。

再后面是反向传播和梯度下降，我们先从简单的线性方式说起（只有加法和乘法），而且用代入数值的方式来消除对公式的恐惧心理。然后会说到分层的复杂（非线性）函数的反向传播，同样用数值代入方式手推反向过程。

梯度下降是神经网络的基本学习方法，我们会用单变量和双变量两种方式说明，配以可视化的图解。再多的变量就无法用可视化方式来解释了，所以我们力求用简单的方式理解复杂的事物。

本部分最后是损失函数的讲解，着重说明了神经网络中目前最常用的均方差损失函数（用于回归）和交叉熵损失函数（用于分类）。
