<!--Copyright Â© Microsoft Corporation. All rights reserved.
  Applicable to [License](https://github.com/Microsoft/ai-edu/blob/master/LICENSE.md) copyright license-->

# Chapter 15 Network Optimization

As networks become more complex, training becomes more and more difficult, and the time it takes becomes longer and longer. The reasons may be:

- Many parameters
- Large amounts of data
- The gradient disappears
- The loss function has a gentle slope

In order to solve the problems listed above, scientists have studied the performance of networks in depth and found methods which can more or less improve the training of DNNs:

- Weight matrix initialization
- Batch normalization
- Gradient descent optimization algorithm
- Adaptive learning rate algorithm

Of course, there are more methods which are not listed here, so only these common methods are given for your reference.
