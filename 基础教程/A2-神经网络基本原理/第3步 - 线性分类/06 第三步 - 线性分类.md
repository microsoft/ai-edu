<!--Copyright © Microsoft Corporation. All rights reserved.
  适用于[License](https://github.com/Microsoft/ai-edu/blob/master/LICENSE.md)版权许可-->

# 第三步  线性分类

## 摘要

分类问题在很多资料中都称之为逻辑回归，Logistic Regression，其原因是使用了线性回归中的线性模型，加上一个Logistic二分类函数，共同构造了一个分类器。我们在本书中统称之为分类。

神经网络的一个重要功能就是分类，现实世界中的分类任务复杂多样，但万变不离其宗，我们都可以用同一种模式的神经网络来处理。

本部分中，我们从最简单的线性二分类开始学习，包括其原理，实现，训练过程，推理过程等等，并且以可视化的方式来帮助大家更好地理解这些过程。

在本部分中，我们将利用学到的二分类知识，实现逻辑与门、与非门，或门，或非门。

做二分类时，我们一般用Sigmoid函数做分类函数，那么和Sigmoid函数长得特别像的双曲正切函数能不能做分类函数呢？我们将会探索这件事情，从而对分类函数、损失函数、样本标签有更深的理解。

然后我们将进入线性多分类的学习。多分类时，可以一对一、一对多、多对多，那么神经网络使用的是哪种方式呢？

Softmax函数是多分类问题的分类函数，通过对它的分析，我们学习多分类的原理、实现、以及可视化结果，从而理解神经网络的工作方式。
