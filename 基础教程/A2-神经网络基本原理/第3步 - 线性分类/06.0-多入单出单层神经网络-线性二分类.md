<!--Copyright © Microsoft Corporation. All rights reserved.
  适用于[License](https://github.com/Microsoft/ai-edu/blob/master/LICENSE.md)版权许可-->
  
# 第6章 多入单出的单层神经网路 - 线性二分类

## 6.0 线性二分类问题

### 6.0.1 提出问题

在中国象棋棋盘中，楚河汉界将两个阵营的棋子分隔开，而这一模型的原型是公元前206年前后的楚汉相争。当时刘邦和项羽麾下的城池，在中原地区的地理位置示意图如图6-1所示，部分样本数据如表6-1所示。

<img src="./img/6/binary_data.png" width="400" />

图6-1 样本数据可视化

0. 红色圆点，楚，项羽的城池
1. 绿色叉，汉，刘邦的城池

表6-1 样本数据抽样

|样本序号|$X_1$:经度相对值|$X_2$:纬度相对值|$Y$:1=汉, 0=楚|
|---|---|---|---|
|1|0.325|0.888|1|
|2|0.656|0.629|0|
|3|0.151|0.101|1|
|4|0.785|0.024|0|
|...|...|...|...|
|200|0.631|0.001|0|

我们在上一章学习了特征归一化的方法。在本例中，中原地区的经纬度坐标其实应该是一个两位数以上的实数，比如 $(35.234, -122.455)$。为了简化问题，我们已经把它们归一化到 $[0,1]$ 之间了。

问题：

1. 经纬度相对坐标值为 $(0.58,0.92)$ 时，属于楚还是汉？
2. 经纬度相对坐标值为 $(0.62,0.55)$ 时，属于楚还是汉？
3. 经纬度相对坐标值为 $(0.39,0.29)$ 时，属于楚还是汉？

读者可能会觉得这个太简单了，这不是有图吗？定位坐标值后在图上一比划，一下子就能找到对应的区域了。但是我们要求用机器学习的方法来解决这个看似简单的问题，以便将来的预测行为是快速准确的，而不是拿个尺子在图上去比划。

另外，本着用简单的例子说明复杂的原理的原则，我们用这个看似简单的例子，是想让读者对问题和解决方法都有一个视觉上的清晰认识，而这类可以可视化的问题，在实际生产环境中并不多见。

### 6.0.2 逻辑回归模型

回归问题可以分为两类：线性回归和逻辑回归。在第二步中，我们学习了线性回归模型，在第三步中，我们将一起学习逻辑回归模型。

逻辑回归（Logistic Regression），回归给出的结果是事件成功或失败的概率。当因变量的类型属于二值（1/0，真/假，是/否）变量时，我们就应该使用逻辑回归。

线性回归使用一条直线拟合样本数据，而逻辑回归的目标是“拟合”0或1两个数值，而不是具体连续数值，所以称为广义线性模型。逻辑回归又称Logistic回归分析，常用于数据挖掘，疾病自动诊断，经济预测等领域。

例如，探讨引发疾病的危险因素，并根据危险因素预测疾病发生的概率等。以胃癌病情分析为例，选择两组人群，一组是胃癌组，一组是非胃癌组，两组人群必定具有不同的体征与生活方式等。因此因变量就为是否胃癌，值为“是”或“否”；自变量就可以包括很多了，如年龄、性别、饮食习惯、幽门螺杆菌感染等。

自变量既可以是连续的，也可以是分类的。然后通过Logistic回归分析，可以得到自变量的权重，从而可以大致了解到底哪些因素是胃癌的危险因素。同时根据该权值可以根据危险因素预测一个人患癌症的可能性。

逻辑回归的另外一个名字叫做分类器，分为线性分类器和非线性分类器，本章中我们学习线性分类器。而无论是线性还是非线性分类器，又分为两种：二分类问题和多分类问题，在本章中我们学习二分类问题。线性多分类问题将会在下一章讲述，非线性分类问题在后续的步骤中讲述。

综上所述，我们本章要学习的路径是：回归问题->逻辑回归问题->线性逻辑回归即分类问题->线性二分类问题。

表6-2示意说明了线性二分类和非线性二分类的区别。

表6-2 直观理解线性二分类与非线性二分类的区别

|线性二分类|非线性二分类|
|---|---|
|<img src="./img/6/linear_binary.png"/>|<img src="./img/10/non_linear_binary.png"/>|

我们先学习如何解决线性二分类为标题，在此基础上可以扩展为非线性二分类问题。
