## 10.6 人工智能设计

人工智能设计（AI design）是指利用人工智能技术来进行设计的一种设计方法。人工智能技术可以帮助设计师在设计过程中自动化一些任务，提高设计效率，并生成更具创意和创新性的设计方案。

### 10.6.1 人工智能改变设计

人工智能（AI）对设计产业产生了很多影响。AI可以帮助设计师更快地生成设计方案，提高工作效率。此外，AI还可以通过分析大量数据来预测设计趋势，从而帮助设计师做出更符合市场需求的设计。在某些情况下，AI还可以自动生成设计方案，减轻设计师的工作负担。总的来说，AI为设计产业带来了许多创新和变革的可能性。AI改变设计的一些关键领域包括：
•	自动化设计生成：AI 可以根据特定需求生成设计概念和布局，为设计师节省时间和精力。
•	个性化：AI 可以分析用户偏好和行为，为个人用户创建个性化设计。
•	设计优化：AI 可以通过分析用户互动并根据数据驱动的洞察提出改进建议，从而帮助优化设计。
•	协同设计：AI 可以通过提供基于现有设计模式和趋势的建议和想法，协助设计师进行创意过程。
这些 AI 的进步使设计师能够更高效地工作，创建更个性化和优化的设计，并探索新的创意可能性。AI 正成为设计师在快速发展的设计领域保持竞争力的必修课。
当下已经有一些设计师开始使用 AI 参与到设计工作当中，不论是否是处在软件行业，例如： 
•	时尚设计师可以使用 AI 生成新的服装设计。例如，他们可以描述所需的风格、颜色和面料， AI 可以创建各种可能设计的图像。设计师可以在这些设计上进行迭代，为他们的系列创作完美的外观。
•	室内设计师可以使用 AI 为客户创建情绪板和可视化效果。例如，他们可以描述所需的风格和色彩方案， AI 可以创建可能的房间布局和家具摆放的图像。客户可以在购买前看到不同家具和颜色搭配在一起的效果。
•	平面设计师可以使用 AI 创建徽标、插图和其他类型的图形。例如，他们可以描述所需的风格和信息， AI 可以创建可能的图形图像。设计师可以尝试不同的想法，为他们的项目找到最佳方案。
•	用户体验设计师可以使用 AI 创建新产品的原型。例如，他们可以描述所需的功能和外观， 通过 AI 快速创建可能的产品设计的草图测试不同的想法并从用户那里获得反馈，进而快速的试错。

### 10.6.2 人工智能设计工具

人工智能设计工具（AI design tools）是利用人工智能技术，帮助设计师进行设计工作的工具。AI 设计工具可以帮助设计师提高设计效率、提升设计质量、拓展设计思路。随着人工智能技术的不断发展，AI 设计工具将会在设计领域发挥越来越重要的作用。下面我会重点介绍几个当下主流的 AI 工具：

 
图10-9 Midjourney logo，图片来源：en.wikipedia.org/wiki/Midjourney

1.	Midjourney
Midjourney 是一款2022年3月面世的AI绘画工具，创始人是 David Holz。这款工具基于 GPT 模型，采用对抗生成网络（GAN）技术实现文本到图像的转换。用户只需输入想到的文字，如“一只红色的猫在草地上玩耍”，Midjourney 就能生成与描述相符的图像。
Midjourney 的使用方式非常简单，用户只需要在聊天框中输入自己想要的画面描述，Midjourney 就能根据这些描述自动生成具有视觉效果的图像。Midjourney 的绘画风格非常独特，因此它生成的图像即使在细节方面也与用户输入的文字描述完全一致。
Midjourney 的优点在于它可以根据用户的文字描述自动生成图像，这使得用户无需具备绘画技能或专业知识即可生成自己想要的图像。此外，Midjourney 还具有快速、高效的特点，可以快速生成大量图像，大大提高了绘画效率。除此之外，我们还可以拿它来：
•	快速生成插画：Midjourney 可以根据设计师的文字描述自动生成图像，这可以帮助设计师快速生成插画，而无需花费大量时间进行手动绘画。设计师可以将生成的图像用于演示、测试和反馈，以更好地了解用户的需求和反馈。
•	提供创意灵感：Midjourney 可以提供多种绘画风格和创意，这可以帮助设计师获得更多的创意灵感，从而设计出更具吸引力和个性化的界面和用户体验。
•	提高设计效率：Midjourney 可以快速生成大量图像，这可以提高设计师的工作效率，缩短设计周期，同时也可以提供更多的选择和可能性，从而更好地满足用户需求。
•	实现更复杂的视觉效果：Midjourney 可以生成非常复杂的视觉效果，例如逼真的材质、光影和动态效果，这可以帮助设计师实现更为逼真和具有吸引力的界面和用户体验。
•	视觉元素库：设计师可以使用 Dall-E 生成的图像构建一个视觉元素库，以便在设计过程中随时调用。

 
图10-10 DALL-E logo，图片来源：en.wikipedia.org/wiki/DALL-E

2.	DALL-E 
DALL-E（也称为DALL-E 2）是一种基于人工智能的图像生成模型，由美国 OpenAI 非营利组织于2021年1月份推出。这种模型可以根据文本提示生成相应的图像，在艺术、设计、广告等领域具有广泛的应用前景。
DALL-E 模型的核心技术是基于 GPT 架构的文本到图像的生成模型，它通过学习大量图像和文本数据，能够理解并生成与文字描述对应的图像。该模型在处理图像时可以捕捉到每个物体的细节，包括形状、颜色、纹理等，同时还能进行合理的组合与布局，生成具有创意和艺术性的作品。
DALL-E 模型的优点在于它能够快速、准确地根据文字提示生成高质量的图像，无需任何额外的图像处理或编辑。此外，该模型还具有高度的灵活性和可定制性，用户可以通过调整文字描述、参数设置等方式来控制生成的图像样式，以满足不同的需求。
对于设计师来说，DALL-E 和 Midjourney 最大的区别在于它们生成的图像风格和质量不同。
DALL-E 是基于 GPT-3 模型的衍生品，可以生成更高分辨率和更真实的图像，更注重于细节和逼真度。它能够捕捉到图像中的复杂结构和纹理，生成的图像质量非常高。由于其生成的真实感很强，因此常常被用于广告、产品渲染等商业设计领域。Midjourney 则是基于 CLIP和 VQGAN 模型的组合，更注重于生成不同艺术风格的图像。它可以根据用户输入的文字描述或图像生成多种艺术风格的图像，包括抽象、手绘、油画等。
总之，对于设计师来说，Midjourney 更具有创意和独特性，适合用于创意设计领域的图像生成。DALL-E更适用于需要高度真实感和细节的设计领域，我们可以根据自己的需求选择合适的工具。

 
图10-11 Adobe Firefly logo，图片来源：en.wikipedia.org/wiki/Adobe_Firefly

3.	Adobe Firefly
Adobe Firefly是Adobe公司推出的一款基于人工智能和机器学习技术的图像生成和处理工具。它能够根据用户输入的文字内容或图像，自动生成相应的图像或艺术作品，并支持多种文件格式和图像处理操作。
Firefly的主要功能包括：
•	文字生成图像：用户可以通过输入文字信息，让Firefly根据文字内容自动生成相应的图像或艺术作品。
•	图像编辑和处理：Firefly支持多种图像编辑和处理的工具，例如裁剪、缩放、旋转、调整色彩等，可以帮助用户快速实现各种图像处理任务。
•	自定义矢量、画笔和纹理：Firefly可以根据用户的自定义需求，生成矢量、画笔和纹理等素材，帮助用户快速实现创意设计。
•	视频编辑和处理：Firefly支持对视频进行编辑和处理，例如添加特效、转场、调色等，可以帮助用户快速实现视频创意和艺术化处理。
Firefly的优点在于它能够根据用户的输入内容自动生成相应的图像或艺术作品，而且生成的图像质量高、速度快，能够帮助用户快速实现各种创意和设计需求。此外，Firefly还具有高度的灵活性和可定制性，用户可以通过调整参数、选择不同的工具和素材等方式来控制生成的图像或艺术作品的效果和质量。
Adobe Firefly、Midjourney 和 DALL-E 都是基于人工智能和机器学习技术的图像生成和处理工具，但它们之间存在一些区别：
•	训练数据和模型：Midjourney 使用的是图像生成模型，其训练数据来自 “Adobe Stock 图像、公开许可的内容以及版权已过期的公共领域内容”。Adobe Firefly 的训练数据来源未被明确提及，但据报道称，它可能也使用了类似的数据集。DALL-E 则使用了一种基于Transformer 的模型，其训练数据来自从互联网上收集的图像。
•	输入方式和生成方式：Midjourney 可以根据用户输入的文字内容生成图像，而不需要输入与图像有关的条件，因此它更加自由和随机。Adobe Firefly 需要输入与图像有关的条件，例如颜色、线条、形状等，才能生成图像，因此它更加可控和精确。DALL-E 需要用户输入文本描述或图像作为条件，才能生成相应的图像。
•	图像风格和质量：Midjourney 生成的图像具有高度的多样性和独特性，但可能存在一定的不稳定性。Adobe Firefly 生成的图像更加可控，符合用户的意愿，但可能缺乏一定的创意和独特性。DALL-E 可以根据用户输入的文本描述或图像生成高质量的图像，但可能存在一定的不稳定性。

 
图10-12 Stable diffusion，图片来源：en.wikipedia.org/wiki/Stable_Diffusion

4.	Stable diffusion 
Stable diffusion 是一种生成式 AI 模型，它使用一种称为扩散建模的过程来创建图像。扩散建模的工作原理是从一个随机图像开始，然后逐渐向其添加噪声，直到它与用户给出的描述相匹配。这个过程会重复进行，直到图像被认为是“稳定”的，也就是说，当添加更多噪声时，它不再发生显著变化。
其他 AI 生成工具，如 DALL-E 2 和 Imagen，使用一种称为生成对抗网络（GANs）的过程来创建图像。GANs 通过训练两个相互对抗的神经网络来工作。一个网络（生成器）负责创建图像，另一个网络（判别器）负责从真实图像中识别出伪造的图像。生成器不断尝试创建更逼真的图像，而判别器则不断尝试识别出伪造的图像。这种竞争过程有助于提高生成器产生的图像质量。
Stable diffusion 和 GANs 有不同的优缺点。Stable diffusion 通常被认为在创建逼真和视觉上吸引人的图像方面更优越。然而，它的速度可能比 GANs 慢，而且控制输出可能更困难。GANs 通常比 Stable diffusion 更快，而且更容易控制。然而，它们有时会创建不真实甚至令人不安的图像。
最终，对于特定任务最好的 AI 生成工具将取决于用户的具体需求。如果真实性和视觉吸引力是最重要的因素，那么 Stable diffusion 可能是更好的选择。如果速度和控制更重要，那么 GAN 可能是更好的选择。
对于设计师来说，Stable Diffusion 的上手难度更高，因为他提供了更多的开放性，它可以允许用户上传各种模型，暴露给用户的功能细节更多，并且也更加可控。所以通常对于有精细化需求的插画设计我们会考虑使用 Stable diffusion，对比起其他的软件来说，它更适合用来做一些需要精准度的设计。
5.	ChatGPT 与 Bard
您可能会好奇说，为什么 ChatGPT 与 Bard 也算是人工智能设计工具呢？其实在设计的过程中 ChatGPT 和 Bard 还真的能帮助我们解决不少的问题。ChatGPT 和 Bard 都是基于大型预训练模型的技术，可以生成文本、翻译语言、编写不同类型的创造性内容，并以一种信息丰富的方式回答问题。
例如通过它们，设计师可以完成以下工作：
•	生成文本：它们可以根据各种提示生成文本，例如帮助我们生成产品的图标，插画和文字。例如，我们可以通过它生成 UI 中的一些文案，或者可以通过重写的命令让 GPT 帮助我们将已有的文案打磨的更贴切。
•	翻译语言：它们可以在 200 多种语言之间进行翻译。例如，我们可以要求 ChatGPT 将“Hello”从英语翻译成西班牙语。这样一个小团队也可以用过国际化的语言包，从而为国际化用户提供更好的用户体验。
•	绘制插画：ChatGPT 可以编写各种创意内容，如插画。我们只需向 ChatGPT 提供一些关于我们想要的内容的详细信息，它就会帮助我们绘制，当前 GPT 的绘画能力还不是非常成熟，我们可以通过 GPT 生成一些专业图像生成工具当中的命令，例如用来输入Midjourney 的 prompt（提示语），中间的过程免除了我们学习 prompt 的成本。
另外，对于设计师而言，一个很大的好处是节约了竞品分析的时间。在过去如果我们要了解一家竞品，除了去使用对方最新的体验之外，我们可能还会希望搜索到一些可以量化的数据了解竞品现在所处的行业地位等。通过AI的协助，我们可以大大加速这个信息搜集的过程。例如：
•	收集竞争对手信息：可以访问和处理来自各种来源的信息，包括网络、社交媒体和新闻文章。这些信息可用于识别竞争对手、他们的产品和服务、目标市场和营销策略。
•	分析竞争对手数据：可以利用其对设计的知识和理解来分析竞争对手数据。这种分析可以帮助设计师识别竞争对手的优势和劣势，以及市场上的机会和威胁。
•	生成洞察：可以利用对竞争对手数据的分析来生成有助于设计师改进自己设计的洞察。这些洞察可能包括新的想法、策略和战术。
•	提供反馈：收集用户对线上产品或同类竞品的反馈。这些反馈可以帮助设计师改进他们的设计，使设计更满足用户的需求。

### 10.6.3 人工智能设计案例

因为Midjourney 没有自己的客户端，要使用 Midjourney 首先我们需要注册 Discord 账户，然后在 Discord 订阅 Midjourney 的服务。要了解 Midjourney，我们可以首先尝试一下它最核心的命令，感受一下它的威力。
 
图10-13 Midjourney prompt，图片来源：Midjourney 官网

如图10-13所示，Imagine 是 Midjourney 当中使用频率最高的一个命令，通过/imagine 这个命令我们可以将文字转化成图片，输入 /imagine prompt: 或从斜杠命令弹出窗口中选择 /imagine 命令。在提示字段中输入我们想要创建的图像的描述，然后发送消息。稍等片刻Midjourney 就会讲对应的图片渲染之后呈现给用户。
如果需要生成更加定制化的图片我们就需要认识一下 prompt的 组成，一般由 一个或多个图像的URL + 一个或多个文本短语 + 一个或多个后缀参数组成；
URL一般是我们上传参考图片的链接，文本短语就是对想要生成的图像的文本描述，后缀参数是控制图像生成的模型版本、宽高比、风格化参数等，其中文本短语和后缀参数是必要条件。
  
图10-14 prompt 参数，图片来源：Midjourney 官网

例如，我希望生成一个乐高风格的梵高插画，就可以输入下面这段描述：
/imagine Starry night made out of lego 
得出的结果如下：
 
图10-15 Midjourney 图片生成结果

对于设计师而言，光自己去探索命令的效率是有限的，这个时候我们应该找一些参考，例如 Midjourney 提供的 Feed 流当中就有社区的 feed，这些图片流是由系统筛选的平台优秀作品，当我们看到感兴趣的作品时可以复制对应的代码，然后贴到自己的输入框当中，原样或者稍作修改，就可以产出非常高质量的效果。
 
图10-16 Midjourney 官方社区探索

例如我当我希望生成一个类似卡通漫画女生作品的时候，我只需要粘贴它的 prompts:
Utopian Visionary, 1980s vibes, risograph pencil illustration by Roy Lichtenstein 
然后粘贴到 Midjourney 当中直接 imagine，就生成了四张风格相似的作品：
 
图10-17 Midjourney 图片生成结果

当然除了最基本的 "Imagine" 命令之外，我们还应该掌握一些功能帮助我们更好的使用 Midjourney，例如当我们生成一张图片之后我们可以点击下方的 U 、V、或者刷新，其中U是英文 upscale 的缩写，代表着放大。例如你觉得这四张图片当中的第二张非常满意，那么就点击U2，Midjourney会帮助你生成具有更多细节版本的第二张图片。V是英文variant的缩写，如果你觉得四张图当中的第三张图挺好，但是希望给予第三张图稍作修改，这个时候可以点击V3，Midjourney 就会帮你生成四张基于当前第三张图片的作品。如果对当前几个生成的结果都不太满意，可以点击刷新按钮。这时 Midjourney 基于同样的 prompts 重新生成4张图片。
对于一个专业设计师来说，掌握这些是不够的，如果需要掌握Midjourney，我们需要了解 Midjourney 的其他参数，例如参数的使用等等。
举个例子，同样的猫，如果我们用不同的参数去描述，就会出现不同的结果，例如当我们输入下面这行命令：
/imagine prompt <any art style> style cat
 
图10-17 Midjourney 图片生成结果， 图片来源：Midjourney 官网

我们会发现不同的用词导致了不同的风格的出现，所以熟悉 prompt 是一个很重要的过程，之后熟练的运用了 prompt 我们才可以将自己脑海中的想法描述出来告诉计算机。当然，熟记 prompt 只是熟练运用 Midjourney 的方法之一，我们也可以借助一些第三方的工具来帮助我们更好的生成 prompts，例如我们可以直接通过 ChatGPT 生成 prompt 然后将生成好的 prompt 直接粘贴到 Midjourney 当中。我们也可以通过一些第三方的网站例如 noonshot.com，可以帮我们通过可视化的方式生成 prompt，降低了我们的学习门槛。
我们发现尽管人工智能设计工具的出现时间较短，但已有一些行业开始将其应用于日常工作，如广告业和游戏设计业。通过AI工具，我们可以快速生成背景图层，将原画师 1-2 天的工作量缩短至10-20分钟。此外，过去制作横幅广告可能需要一位经验丰富的设计师半天的时间，而现在这一过程可以缩短至一个小时之内。掌握AI设计工具正逐渐成为必备技能，因为与其所能创造的价值相比，主流AI设计工具的学习成本微不足道。因此，我们强烈建议设计师们掌握主流的AI设计工具。
随着AI设计工具的普及，设计师们可以更高效地完成工作，提高生产力。这些工具不仅可以帮助设计师们快速生成各种设计元素，还可以为他们提供灵感和创意。此外，AI设计工具还可以帮助设计师们更好地与团队协作，共同完成项目。因此，学习和掌握这些工具对于设计师来说是非常有价值。
