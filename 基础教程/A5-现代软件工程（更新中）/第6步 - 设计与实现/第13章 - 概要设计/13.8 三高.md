
## 13.8 三高


### 13.8.1 高性能

软件设计和实现中，性能是每个设计人员和开发人员都要时刻考虑的问题，尤其是针对那种实时运行的线上服务系统而言，能用 20 毫秒完成的任务，就不要用 30 毫秒。

#### 1. 数据结构

数据结构是最底层的环节。举例来说：当需要经常查找一个数组时，是什么时候用哈希表，什么时候用列表数组？

笔者以前曾经做过试验，当数组元素个数少于 10 个时，用列表数组遍历查找比较快；当元素个数大于 10 个时，用哈希表比较快。因为计算哈希值是需要时间的。

接下来的问题是：有没有比哈希表（即字典）更快的方法？有！那就是利用 ID 直接在内存中定位。比如想获得 ID=3 的数据记录，直接用 DataList[3] 获得即可。这就要求在设计 DataList 时最好是连续的，可以用整数值来表示 ID。

#### 2. 算法

算法和数据结构是相辅相成的，有了数据结构的支持，才有算法的实现。算法要考虑时间复杂度和空间复杂度。如读者都知道的排序算法，其时间复杂度和空间复杂度的比较如表 13.8.1 所示。

表 13.8.1 各种排序算法比较

|排序方法|时间复杂度|空间复杂度|稳定性|
|-|-|-|-|
|插入排序|$O(n^2)$|$O(1)$|稳定|
|希尔排序|$O(n^{1.3})$|$O(1)$|不稳定|
|选择排序|$O(n^2)$|$O(1)$|不稳定|
|冒泡排序|$O(n^2)$|$O(1)$|稳定|
|归并排序|$O(n \log n)$|$O(n)$|稳定|
|快速排序|$O(n\log n)$|$O(\log n)$|不稳定|
|堆排序|$O(n\log n)$|$O(1)$|不稳定|
|计数排序|$O(n+k)$|$O(n+k)$|稳定|
|桶排序|$O(n+k)$|$O(n+k)$|稳定|

有了这张表，读者当然可以很容易地选择性能最好的排序方法。但是，在实际应用中很少有如此“单纯”的问题可以轻松得到答案。比如在 2.3 节中的算法问题，实际上是可以用 $O(n)$ 时间复杂度来解决的，而它利用的就是在上面的数据结构中描述的 ID 定位法。

另外，要对代码中的循环语句保持高度的警惕，它很可能就是性能杀手！

举例来说：在一个统计英语词频的代码中，对每一个段落都使用了 str.split() 函数来做分词，因为每个英文单词之间都有空格或者标点符号。在做性能分析时，发现 split() 函数非常慢，占用了 80% 左右的运行时间，而原因是这个函数需要在内存中分配空间来保存 split 的结果，而且由于不能预先知道分配空间的大小，所以会动态地扩容。这听上去很方便、很自动，但实际上空间的分配、释放就是性能杀手，尤其是在成千上万次的循环中。

另外一个例子，是笔者遇到的计算股票交易数据中某个时间段（比如 5 分钟）之内的起始价、终止价、最高值、最低值、交易量等数据。这听上去很容易：找到一个时间段，比如 10:00~10:05，然后遍历每个交易记录即可。但是，问题在于股票的交易频率非常高，每分钟可能有上万次交易，而且股票有上千支，一年中又有 300 多个交易日，这样循环下来，计算量成几何级数增加。笔者的一个实习生用这种方法写的代码，处理一天的数据需要 20 多分钟。

对于这个问题，很多人会使用 Pandas 来承载数据，但是 Pandas 在易用性上的友好会降低它的性能，所以应该采用最原始的 Numpy 数组来加载数据，然后用 numpy.sum()、numpy.max()、numpy.min() 等函数一次搞定一批数据，避免最内层的遍历。笔者用这种方法写的代码处理一天的数据只需要 10 几秒。


#### 3. 缓存

“用空间换时间”就是缓存策略。缓存有两种：读缓存和写缓存，主要是针对磁盘而言。

读缓存：因为数据量较大时，不能把所有数据都放入内存，只能临时从磁盘读取。由于磁盘读的速度较慢，当遇到频繁读取时，就会有瓶颈产生。此时，可以考虑把常用的那部分数据经过加工处理后放到内存中当作缓存，不需要临时查询数据库。

写缓存：写磁盘的速度比读磁盘的速度还要慢，而且马虎不得，读错一次的话还有机会改正，写错一次就再也没机会。因此写磁盘是一个非常重要但不紧急的任务，所以可以考虑异步缓存，即：先把数据写到内存中的消息队列中，由后台进程从消息队列中读出来，再写入到磁盘数据库中。这种机制仅在刚写完消息队列就要立刻从磁盘里查询时会由于时效性问题而出错，但是不是致命错误，只是有延迟而已。

#### 4. 并发

对于计算密集型的问题，并发意味着可以利用多颗 CPU 的优势，让它们同时完成不同的任务，即多进程或多线程。但是请注意编程语言的支持情况，如 Python 没有真正的多线程，所有的线程都是在一颗 CPU 上跑的。其它如 C++, JAVA, C# 都可以让多线程在多 CPU 上分享。

多线程编程相对较容易，尤其是在数据共享时在进程内线程间简单地加锁即可，而且系统开销比较小。但是传统的 Linux 系统对线程的支持没有 Windows 系统好，当然主要是因为内核优化和编译器优化上，Linux 还是以进程为主。笔者曾经在 Linux 上用多线程调用系统时间函数时出错，因为该函数要求线程安全。进程的开销比较大，但是相对安全。

所以，在 Windows 上用线程方便一些，在 Linux 上用进程保险一些。但是两者最好都用线程池或进程池机制比较好，避免频繁创建、销毁线程或进程的开销，而且能控制一台机器内线程和进程的总数量。

对于存储密集型的问题，并发意味着可以把数据拷贝到多个副本数据库中，在读取时可以根据负载均衡策略从不同的数据库读取不同的内容。但是在写入时，只能写入主数据库，然后同步到副本数据库，如 12.3.4 节中所讲。

#### 5. 集群

当我们利用以上手段在单台机器上优化，但是眼看着就要 CPU 达到满负荷时，就需要多台计算机做集群了，这些计算机都具有相同的服务功能。实际上，当单台计算机的负荷达到 70% 左右时，就应该考虑集群。

所谓集群，就是一台机器的多个副本（多台机器）具备相同的能力，由一个负载均衡器来分配任务，负载均衡的算法有很多种，可以分为静态算法和动态算法两类：

- 静态负载均衡算法
  - 轮询（Round Robin）：服务器按照顺序循环接受请求。
  - 随机（Random）：随机选择一台服务器接受请求。
  - 权重（Weight）：给每个服务器分配一个权重值，根据权重来分发请求到不同的机器中。
  - IP哈希（IP Hash）：根据客户端IP计算Hash值取模访问对应服务器。
  - URL哈希（URL Hash）：根据请求的URL地址计算Hash值取模访问对应服务器。
  - 一致性哈希（Consistent Hash ）：采用一致性Hash算法，相同IP或URL请求总是发送到同一服务器。

- 动态负载均衡算法
    - 最少连接数（Least Connection）：将请求分配给最少连接处理的服务器。
    - 最快响应（Fastest Response）：将请求分配给响应时间最快的服务器。
    - 观察（Observed）：以连接数和响应时间的平衡为依据请求服务器。
    - 预测（Predictive）：收集分析当前服务器性能指标，预测下个时间段内性能最佳服务器。
    - 动态性能分配（Dynamic Ratio-APM）：收集服务器各项性能参数，动态调整流量分配。
    - 服务质量（QoS）：根据服务质量选择服务器。
    - 服务类型（ToS）: 根据服务类型选择服务器

#### 6. 分布式

集群能解决大部分问题，但是当一种计算密集型的应用无法在集群上应用时，就要考虑分布式了。不能让多台计算机干一件事，而是把一个大任务分成不同的子任务，让每台计算机做不同的事，然后把结果合并。

比如：神经网络训练，把训练数据等分成若干份，每台计算机上接收一份数据做一次正向计算和一次反向传播，然后把参数训练结果告诉主机；主机把参数做一个平均，再连同数据发送给多台计算机，做下一次训练。



### 13.8.2 高可用性

- 持续可用性（Availability）：指系统长时间无故障运行的能力，与可靠性相关联，常将其纳入可靠性中。

- 可靠性（Reliability）：软件系统在一定的时间内无故障运行的能力。


### 13.8.3 可扩展性

可扩展性和可伸缩性很容易混淆

- 可扩展性（Flexibility）：软件因适应新需求或需求变化而增加新功能的能力，也称为灵活性。

- 可伸缩性（Scalability）：指当用户数和数据量增加时，软件系统维持高服务质量的能力。例如，通过增加服务器来提高能力。


可伸缩性
安全性

可靠性


https://blog.csdn.net/hguisu/article/details/78259898



设计原则
https://blog.csdn.net/danpu0978/article/details/107274524



