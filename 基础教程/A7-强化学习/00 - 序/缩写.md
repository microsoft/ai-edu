


|英文符号或缩写|英文单词或全拼|中文含义|
|-|-|-|
|$A,a$|Action|动作，$A$ 表示动作集合，$a$ 表示动作实例|
|DP|Dynamic Programming|动态规划|
|$G$|Gain, Returns|回报，是收益的累积|
|MC|Mento Carlo|蒙特卡洛方法|
|MP|Markov Property|马尔可夫性质|
|MRP|Markov Reward Process|马尔科夫奖励过程|
|MDP|Markov Decision Process|马尔科夫决策过程|
||On-Policy|同轨策略，同策略，在线策略|
||Off-Policy|离轨策略，异策略，离线策略|
|$\pi$|Policy|策略|
|$\pi_*$|Best Policy|最优策略|
|$Q,q$|Action Value|动作价值函数|
|$Q_\pi,q_\pi$|Action Value under Policy|策略 $\pi$ 下的动作价值函数|
|$Q_*,q_*$|Optimal Action Value|最优（策略）动作价值函数|
|$R,r$|Reward|收益或奖励|
|$S,s$|State|状态，$S$ 表示状态集合，$s$ 表示状态实例|
|$V,v$|State Value|状态价值函数|
|$V_\pi,v_\pi$|State Value under Policy|策略 $\pi$ 下的状态价值函数|
|$V_*,v_*$|Optimal State Value|最优（策略）状态价值函数|

大小表示集合，小写表示实例。
