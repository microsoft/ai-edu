
## 10.2 价值评估

在 6.3 节中，已经学习过如何使用最朴素的蒙特卡洛方法来评估价值函数。本小节学习使用蒙特卡洛法估算 MRP 下的价值函数 $V$，将要接触到一种算法：首次访问法。需要说明的是，这种算法同样适用于估算 MDP 下的价值函数 $V_\pi, Q_\pi$。

### 10.2.1 提出问题

#### 安全驾驶问题中的状态价值函数估算方法

首先要回忆一下，在 MRP 中，因为没有牵涉到动作问题，所以只有状态价值函数的概念。

在第六章中，针对 MRP 问题，我们曾经使用蒙特卡洛方法估算过“安全驾驶问题”中的状态价值函数。当时给读者留下的印象可能是：

- 这种方法怎么运行起来那么慢？
- 因为要采样很多次才能基本稳定下来，否则两次试验之间的差别特别大，那么到底采样多少次才算合理？
- 这种方法怎么能保证准确？有没有基准可以比较？
- 最终得到的结果的可信度有多高？

在 6.3 节中，我们根据回报 $G$ 的定义：

$$
G_t = R_{t+1}+\gamma R_{t+2}+\gamma^2 R_{t+3}+ \cdots +\gamma^{T-t-1} R_{T}
\tag{10.2.1}
$$

以及价值函数 $V$ 的定义：

$$
v_t(s) = \mathbb E [G_t | S_t = s]
\tag{10.2.2}
$$

然后使用最朴素的蒙特卡洛采样法初步计算出了安全驾驶问题的各个状态的价值函数。简述其过程如下：

1. 使用蒙特卡洛采样，每次采样都需要指定一个初始状态 $s_0$，然后开始在幕内循环；
2. 得到一个 $R$ 后，累积计算 $G = G + \gamma^{t-1}R$，直到幕内循环结束（到 $T$），得到式（10.2.1）的计算结果；
3. 进行下一次采样，$G$ 值清零后再用 step 2 的循环重新计算 $G$ 值并累积；
4. 最后求 $G$ 的平均（数学期望）得到 $v_t(s_0)$，即式（10.2.2）。

这种方法的特点是：
- 易理解，完全按照定义来计算；
- 省空间，不需要记录中间状态，来了一个 $R$ 后立刻计算，然后扔掉，只保留 $G$ 值；
- 随着幕数的增加，会更逼近真实值；
- 每次多幕循环只计算一个状态的价值；
- 遍历状态并在环境控制下重复多次，速度慢；
- 浪费了中间的采样结果。

#### 充分利用样本数据

聪明的读者可能会发现一个问题：如果不“从头”开始，而是从第二个、第三个状态开始计算，是不是就能在一次采样中就可以得到很多状态的 $G$ 值呢？

<center>
<img src='./img/MC-1.png'>

图 10.2.1 重复利用样本来计算不同时刻/状态的回报值
</center>


如图 10.2.1 所示，从 $S_0$ 开始一幕的采样，到 $T$ 为止结束，得到 $R_1,\cdots,R_T$ 的序列后：
- 第一行：固然可以从 $R_1$ 开始计算出 $G_0$。
- 第二行：但是如果从 $R_2$ 开始，不就能计算出 $G_1$ 了吗？
- 第三行：同理，还可以计算出这一采样序列中的任意的 $G_t$ 出来。

这样的话利用一次采样结果可以计算出很多状态的 $G$ 值，会大幅提高算法的效率。当然，这就需要把每一幕的采样结果记录下来，计算完所有可能的 $G$ 后，扔掉这一幕记录，再进行下一幕的采样。


#### 用贝尔曼方程得到解析解

在第六章时，我们还没有学习贝尔曼方程（第七章的内容），所以当时使用了蒙特卡洛法依靠大量的采样来计算 $G$ 值。由于安全驾驶问题实际上是有一个模型的，所以可以利用贝尔曼方程得到该问题的“近似真实解”，并以此为基准（Ground Truth）来衡量算法的性能。而性能又包括两个方面：1. 速度；2. 准确度。需要在这二者之间寻找平衡。

下面是用贝尔曼方程的矩阵法计算出来的状态价值函数值 $V$（精确到小数点后两位）。

【代码位置】MC_102_SafetyDrive_DataModel.py

```
状态价值函数计算结果(数组) : [ 1.03  1.72  2.72  3.02 -5.17 -6.73  6.   -2.37 -1.    5.    0.  ]
Start:       1.03
Normal:      1.72
Pedestrians: 2.72
DownSpeed:   3.02
ExceedSpeed:-5.17
RedLight:   -6.73
LowSpeed:    6.0
MobilePhone:-2.37
Crash:      -1.0
Goal:        5.0
End:         0.0
```

#### 性能衡量算法 RMSE

RMSE - Root Mean Square Error，均方根误差，用于比较观测值与真实值之间的偏差，通常不是比较两个标量，而是比较两个数组。比如，可以用贝尔曼方程的矩阵法计算出来的状态价值数组做为基准值，用蒙特卡洛法估算出来的数组值 $X$与基准值之间 $Y$ 计算 RMSE。

$$
RMSE = \sqrt{\frac{1}{n} \sum_{i=1}^n (x_i-y_i)^2} \tag{10.2.3}
$$

其中：

- $n$ 为数组元素个数；
- $x_i$ 为观测值；
- $y_i$ 为真实值。

代码实现为：

```python
def RMSE(x, y):
    err = np.sqrt(np.sum(np.square(x - y))/y.shape[0])
    return err
```

比如，假设真实值为 $y=[1,2,3]$，观测值为 $x=[1.1,2,2.9]$，则：$RMSE=\sqrt{[(1.1-1)^2+(2-2)^2+(2.9-3)^2]/3} \approx 0.08$。

有一些资料上把 $n$ 解释为观测次数，其实是不对的。另外，在式（10.2.3）中的 $x,y$ 是可以对调的，不影响计算结果。


### 10.2.2 首次访问法

比如在一个采样序列中，有如下状态序列数据：Episode=[s_a, s_b, s_c, s_a, s_d, s_b], $\tau=6$。

- 首次访问法在倒序遍历到最后那个 $s_b$ 时，$t=\tau-1=5$，先检查 $s_b$ 是否在 Episode[0:5] 中；在本例中 Episode[0:5] 含有 $s_b$，所以就不会把这个 $t$ 上的 $G_t$ 值记录到 $G$ 的累积值中。
- $t=4$，$s_d$ 在 Episode[0:4] 中不存在，叫做首次访问，记录其 $G_t$ 值；
- $t=3$，$s_a$ 在 Episode[0:3] 中存在，不记录其 $G_t$ 值；
......
在这个例子中，最终会计算的是 $s_a, s_b, s_c, s_d$ 四个状态的 $G$ 值。

马尔科夫链的环状结构会使得这种情况非常常见，显然第一个 $s_a$ 和 第四个 $s_a$ 在时域 $t$ 上应该具有不同的价值。但是从全局/静态角度看，它们又应该具有相同的价值。Sutton 在研究了这个问题后，认为根据大数定律，首次访问法的方差以 $1/\sqrt{n}$ 的速度收敛。

#### 算法描述

【算法 10.2】首次访问型蒙特卡洛法。

下面的伪代码中，$\leftarrow$ 表示赋值，$\Leftarrow$ 表示追加列表。

---

输入：起始状态 $s,\gamma$, Episodes
初始化：$G(S) \leftarrow 0, N(S) \leftarrow 0$
多幕 Episodes 循环：
　　列表置空 $Episode = [\ ] $ 用于存储序列数据 $(s,r)$
　　幕内循环直到终止状态：
　　　　从 $s$ 根据环境模型得到 $s',r$ 以及是否终止的标志
　　　　$Episode \Leftarrow (s',r)$
　　　　$s \leftarrow s'$
　　$G_t \leftarrow 0$
　　对 $Episode$ 从后向前遍历, $t=\tau-1,\tau-2,...,0$
　　　　取出 $s_t,r_t$
　　　　$G_t \leftarrow \gamma G_t+r_t$
　　　　如果 $s_t$ 不在 $s_0,s_1,\cdots,s_{t-1}$ 中，即首次访问：
　　　　　　$G(s_t) \leftarrow G(s_t)+G_t$
　　　　　　$N(s_t) \leftarrow N(s_t)+1$
$V(S) \leftarrow G(S) / N(S)$
输出：$V(S)$

---

#### 算法说明

图 10.2.2 是算法 10.2.1 的说明。

<center>
<img src="./img/MC-2.png">

图 10.2.2 每次访问法算法说明
</center>

把这张图与图 6.3.1 做比较，就可以发现橙色部分的“计算顺序”是不同的。其中，状态下标 $_S,_N,_L,_G,_E$ 等是安全驾驶问题中对应的状态的缩写，在这里无关紧要，但它们是一个真实的序列。


#### 算法实现

【代码位置】MC_102_FirstVisit.py

```Python
# MC1-FirstVisit 首次访问法
def MC_FirstVisit(dataModel, start_state, episodes, gamma):
    Value = np.zeros(dataModel.nS)  # G 的总和
    Count = np.zeros(dataModel.nS)  # G 的数量
    for episode in tqdm.trange(episodes):   # 多幕循环
        TrajectoryState = []        # 一幕内的状态序列
        TrajectoryReward = []       # 一幕内的奖励序列
        s = start_state
        is_end = False
        while (is_end is False):    # 幕内循环
            next_s, r, is_end = dataModel.step(s)   # 从环境获得下一个状态和奖励
            TrajectoryState.append(s.value)
            TrajectoryReward.append(r)
            s = next_s
        assert(len(TrajectoryState) == len(TrajectoryReward))
        num_step = len(TrajectoryState)
        G = 0
        # 从后向前遍历计算 G 值
        for t in range(num_step-1, -1, -1):
            s = TrajectoryState[t]
            r = TrajectoryReward[t]
            G = gamma * G + r
            if not (s in TrajectoryState[0:t]):# 是否首次访问
                Value[s] += G     # 值累加
                Count[s] += 1     # 数量加 1
    
    Count[Count==0] = 1 # 把分母为0的填成1，主要是终止状态
    return Value / Count    # 求均值
```
与每次访问法代码不同的是，上述代码使用了两个 Trajectory 来分别记录状态序列和奖励序列（当然这二者是同步的），便于在判断是否首次访问时简单易行。


### 10.2.3 运行结果比较

#### 运行结果

首次访问法的运行结果：

```
gamma = 1.0
状态价值函数计算结果(数组) : [ 1.03  1.71  2.73  2.83 -5.2  -6.71  6.   -2.28 -1.    5.    0.  ]
Start:       1.03
Normal:      1.71
Pedestrians: 2.73
DownSpeed:   2.83
ExceedSpeed:-5.2
RedLight:   -6.71
LowSpeed:    6.0
MobilePhone:-2.28
Crash:      -1.0
Goal:        5.0
End:         0.0
耗时 : 4.39701247215271
误差 = 0.06336656060380948
```

#### 几种算法的运行结果比较

表 10.2.1  $\gamma=1$ 时的状态值计算结果比较

|状态|矩阵法(基准值)|顺序计算法|首次访问法|
|-|-:|-:|-:|-:|
|出发 Start|           1.03|1.11|1.03|
|正常行驶 Normal|      1.72|1.52|1.71|
|礼让行人 Pedestrians| 2.72|2.70|2.73|
|闹市减速 DownSpeed|   3.02|2.79|2.83|
|超速行驶 ExceedSpeed| -5.17|-5.19|-5.2|
|路口闯灯 RedLight|    -6.73|-6.71|-6.71|
|小区减速 LowSpeed|     6.00|6.00|6.00|
|拨打电话 MobilePhone| -2.37|-2.51|-2.28|
|发生事故 Crash|       -1.00|-1.00|-1.00|
|安全抵达 Goal|        5.00|5.00|5.00|
|终止 End|              0.00| 0.00|0.00|
|**误差 RMSE**|-|**0.102**|**0.063**|
|**总采样次数**|-|**50000**|**100000**|
|**耗时**|-|**7.37**|**4.70**|


可以看到，改进的算法在速度上和精度上都比原始算法要好。最后一行不是状态值，是 RMSE 的误差值，原始顺序计算法误差为 0.102，改进算法为 0.063 和 0.061，越小越好。

从性能上看，第 6 章介绍的顺序计算法对每个状态做了 5000 次采样，一共 10 个有效状态，所以就是 50000 次采样。首次访问法对所有状态（混合）一共做了 20000 次采样，以每幕平均 5 个状态来估算，就有至少 100000 次采样，结果自然会比顺序计算法要准确。

几种算法的耗时值其实并不准确，因为每次运行都有不同的值，但是可以确定的是，首次访问法比顺序计算法性能要好，因为重复利用了采样结果。
