
## 3.3 转移概率矩阵

### 3.3.1 连续转移

**转移概率矩阵**，又称为**状态分布矩阵**，它用矩阵的形式定义了从任意事件（状态）转换到另一个事件（状态）的概率。

如何得到这个矩阵呢？

在代码 RentCar_2_OneByOne.py 中，已经通过双重循环，逐个计算从指定门店租出到指定门店还车的概率来得到该矩阵。但其实不用这么麻烦，利用 numpy 数组的一些特性，可以用更简单的代码一次搞定所有门店的数据：

【代码位置：RentCar_4_Matrix.py】

```Python
def calculate_matrix(n_states, data_array):
    # 定义一个 n x n 的数组（矩阵）
    P_counter = np.zeros((n_states, n_states))
    rows = data_array.shape[1]  # 获得记录行数
    for i in range(rows):   # 一共100行记录
        data_list = data_array[i].ravel().tolist()  # 数组变成列表
        # 把 ABCD 变成 0123
        X = [ord(x)-65 for x in data_list]
        for i in range(len(X)-1):
            rent_from = X[i]        # 第 0 天
            return_to = X[i+1]      # 第 1 天
            # 对应位置计数加 1
            P_counter[rent_from, return_to] += 1
    #endfor
    # 计算各列之和
    sum = np.sum(P_counter, axis=1, keepdims=True)
    print("各个状态出现的次数:\n",sum)
    P = P_counter / sum
    return P
```

运行上述代码，得到：

```
各个状态出现的次数:
 [[2677.]
 [3013.]
 [1555.]
 [2655.]]
概率转移矩阵:
[[0.1 0.3 0.  0.6]
 [0.8 0.  0.2 0. ]
 [0.  0.9 0.1 0. ]
 [0.  0.3 0.3 0.4]]
```

这样就得到了一个矩阵：

$$
P = 
\begin{pmatrix}
P_{11} & P_{12} & P_{13} & P_{14}
\\
P_{21} & P_{22} & P_{23} & P_{24}
\\
P_{31} & P_{32} & P_{33} & P_{34}
\\
P_{41} & P_{42} & P_{43} & P_{44}
\end{pmatrix}= 
\begin{pmatrix}
0.1 & 0.3 & 0.0 & 0.6
\\
0.8 & 0.0 & 0.2 & 0.0
\\
0.0 & 0.9 & 0.1 & 0.0
\\
0.0 & 0.3 & 0.3 & 0.4
\end{pmatrix}
\tag{3.3.1}
$$

这就相当于把图 3.2.1 变成表 3.3.1，方便使用矩阵计算来解决问题。

表 3.3.1 转移概率表

|P: 从$\rightarrow$到|A|B|C|D|转出总和|
|:-:|-|-|-|-|-|
|**A**|0.1|0.3|0.0|0.6|1.0|
|**B**|0.8|0.0|0.2|0.0|1.0|
|**C**|0.0|0.9|0.1|0.0|1.0|
|**D**|0.0|0.3|0.3|0.4|1.0|
|**转入总和**|0.9|1.5|0.6|1.0|4.0|

数据解读：

- 是一个 $n \times n$ 的方阵（中间的 4x4 区域）。
- 矩阵各元素都是非负的，即：$0 \le P_{i,j} \le 1$。
- 各行元素（输出概率）之和为 1，即：$\sum^n_{j=1} P_{i,j}=1$。
- 对于输入概率总和没有限制，但是最终的总和（右下角）在行列上肯定应该一致，都是4.0（因为有个 4 个门店），即：$\sum_{i=1}^n \sum_{j=1}^n P_{i,j} = n$。


而对于一个有 $n$ 个状态的通用问题，矩阵形式是：

$$
P = 
\begin{pmatrix}
P_{11} & \cdots & P_{1n}
\\
\vdots & \ddots & \vdots
\\
P_{n1} & \cdots & P_{nn}
\end{pmatrix}
\tag{3.3.2}
$$

### 3.3.2 迭代计算

下面我们使用矩阵计算来代替复杂的循环逻辑。

1. 首先定义第 0 天的初始向量：

    $$
    X_0=(0,1,0,0)
    $$

    第二个元素为 1，表示豪华跑车目前在 B 门店。

2. 该车第 1 天在哪个门店出现的问题可以转换为：

$$
X_1 = X_0 P=(0, 1 , 0 , 0)
\begin{pmatrix}
0.1 & 0.3 & 0.0 & 0.6
\\
0.8 & 0.0 & 0.2 & 0.0
\\
0.0 & 0.9 & 0.1 & 0.0
\\
0.0 & 0.3 & 0.3 & 0.4
\end{pmatrix}=
(0.8,\ 0.0,\ 0.2,\ 0.0)
$$

3. 该车第 2 天在哪个门店出现的问题可以递归计算出：

$$
X_2 = X_1 P=(0.8,\ 0.0,\ 0.2,\ 0.0)
\begin{pmatrix}
0.1 & 0.3 & 0.0 & 0.6
\\
0.8 & 0.0 & 0.2 & 0.0
\\
0.0 & 0.9 & 0.1 & 0.0
\\
0.0 & 0.3 & 0.3 & 0.4
\end{pmatrix}=
(0.08, \ 0.42, \ 0.02, \ 0.48)
$$

上述结果和表 3.2.1 完全一致。

推广到一般情况，计算第 $n+1$ 天的概率时，需要使用第 $n$ 天的结果

$$
X_{n+1}=X_n P \tag{3.3.3}
$$


我们可以很方便地写出代码，来计算第 5 天的出现概率：

【代码位置：RentCar_5_OneByOne.py】

```python
P = np.array([
    [0.1, 0.3, 0.0, 0.6],
    [0.8, 0.0, 0.2, 0.0],
    [0.0, 0.9, 0.1, 0.0],
    [0.0, 0.3, 0.3, 0.4]
])

def calculate_day(X, P, day):
    X_n = X.copy()
    for i in range(day+1): # 因为是从0开始，所以day要+1
        print(str.format("day {0}: {1} ", i, X_n))
        X_n = np.dot(X_n, P)

if __name__=="__main__":
    X = np.array([0,1,0,0]) # 该车第0天在B店
    calculate_day(X, P, 5)  # 计算第5天在哪里
```

运行代码 RentCar_5_OneByOne.py，得到：

```
day 0: [0 1 0 0] 
day 1: [0.8 0.  0.2 0. ] 
day 2: [0.08 0.42 0.02 0.48]
day 3: [0.344 0.186 0.23  0.24 ]
day 4: [0.1832 0.3822 0.1322 0.3024]
day 5: [0.32408 0.26466 0.18038 0.23088]
```

OK！经理的问题彻底解决了：在第 5 天的时候，该豪华跑车在 4 个门店出现的概率依次是：$[0.32408,\ 0.26466,\ 0.18038,\ 0.23088]$

可以再看一下第2天的数据（day 2），也与前面的手工计算结果一致。

### 3.3.3 K-步转移概率矩阵

从上面的例子我们可以看到，只有一步的转移概率是不能满足实际需要的，通常需要迭代计算才能知道 K 步后的情况如何，虽然这已经比没有矩阵时的复杂循环逻辑好了很多。

比如，5 步后的概率应该是：

$$
X_5 = X_4 P=(X_3P)P=((X_2P)P)P=(((X_1P)P)P)P=((((X_0P)P)P)P)P=X_0 P^5
$$

$P^5$ 可以定义为 5 步转移概率矩阵，则 K-步转移概率为：

$$
P^K = 
\begin{pmatrix}
P_{11} & \cdots & P_{1n}
\\
\vdots & \ddots & \vdots
\\
P_{n1} & \cdots & P_{nn}
\end{pmatrix}^K
\tag{3.3.4}
$$

代码如下：

【代码位置：RentCar_6_KStep.py】


```Python
# 计算K步转移概率矩阵        
def K_step_matrix(P, K):
    Pk=P.copy()
    for i in range(K-1):    # 自乘次数不是k次，而是k-1次
        Pk=np.dot(Pk,P)
    return Pk
```
读者可能会注意到循环次数是 K-1，而不是 K。假设我们计算 K=2 步转移矩阵，那么一步矩阵 P 和自己做 1 次矩阵相乘就可以了，而不是做 2 次。所以 K 步矩阵只需要做 K-1 次矩阵相乘。另外一个细节是 np.dot(P,Pk) 和 np.dot(Pk,P) 都会得到相同的结果，读者可以自行验证。

得到 K-步转移矩阵后，可以用如下代码简单地直接计算第 5 天的情况：

```Python
if __name__=="__main__":
    X = np.array([0,1,0,0])
    P5 = K_step_matrix(P, 5)
    print(P5)
    X5 = np.dot(X, P5)
    print(X5)
```

运行后得到结果：

```
5步转移概率矩阵:
 [[0.25585 0.31989 0.14028 0.28398]
  [0.32408 0.26466 0.18038 0.23088]
  [0.19728 0.36459 0.14005 0.29808]
  [0.26448 0.29469 0.15843 0.2824 ]]
第 5 天的情况： [0.32408 0.26466 0.18038 0.23088]
```

与上面的迭代方法计算结果一致。

观察打印输出中得到的 5 步转移概率矩阵的数值：
- 仍然是 4x4，表示 4 种状态之间的转移。
- 每行数字相加为 1，表示移出概率。

那么可以定义 K-步转移概率的定义为：

$$
P_{i,j}(t,t+k)= \mathbb P[X_{t+k}=a_j|X_t = a_i] \tag{3.3.5}
$$

$$
\sum_{j=1}^n P_{i,j}(t,t+k)=1, \ (i=1,2,...,n) \tag{3.3.6}
$$

其中，$n$ 为状态数量，$i,j$ 为行列序号，$a$ 为状态。

当转移概率$P_{i,j}(t,t + k)$只与 $i,j$ 及时间间距 $k$ 有关时，称转移概率具有平稳性。同时也称马尔可夫链是齐次的或时齐的。

### 3.3.4 更多步的情况

从 K-步可以向更远的地方思考，如果 K 为无穷大时，这个转移概率矩阵是什么情况呢？

同样可以用代码做一个试验：

【代码位置：RentCar_7_Convergence.py】

```Python
def Check_Convergence(P):
    P_curr = P.copy()
    for i in range(100000):
        P_next=np.dot(P,P_curr)
        print("迭代次数 =",i+1)
        print(P_next)
        if np.allclose(P_curr, P_next):
            break
        P_curr = P_next
    return P_next

if __name__=="__main__":
    Pn = Check_Convergence(P)
```

注意，在代码中使用了 np.allclose(P_curr, P_next) 来判断上一次迭代结果和本次迭代结果的差值，如果小于1e-6则认为已经收敛，停止循环。运行过程如下所示：

```
迭代次数 = 1
[[0.25 0.21 0.24 0.3 ]
 [0.08 0.42 0.02 0.48]
 [0.72 0.09 0.19 0.  ]
 [0.24 0.39 0.21 0.16]]
迭代次数 = 2
[[0.193 0.381 0.156 0.27 ]
 [0.344 0.186 0.23  0.24 ]
 [0.144 0.387 0.037 0.432]
 [0.336 0.309 0.147 0.208]]

......

迭代次数 = 27
[[0.26966338 0.30337037 0.1573036  0.26966265]
 [0.26966195 0.30337167 0.15730289 0.26966349]
 [0.26966412 0.3033697  0.15730396 0.26966222]
 [0.26966285 0.30337085 0.15730334 0.26966296]]
迭代次数 = 28
[[0.26966264 0.30337105 0.15730323 0.26966309]
 [0.26966353 0.30337024 0.15730367 0.26966257]
 [0.26966217 0.30337147 0.157303   0.26966336]
 [0.26966296 0.30337075 0.15730339 0.2696629 ]]
```

一个有趣的现象是，当迭代了28次后就已经**收敛**到很小的误差了，概率变化趋于平稳。可以认为在经过多次的 “租、还、租、还” 循环后，某辆车在四个门店的出现概率（精确到两位小数）固定为：$[0.27,\ 0.30,\ 0.16,\ 0.27]$。这种收敛并非本问题的特例，而是一种普遍的现象。

从实际应用场景分析：

- 可能是因为 C 店在通州区太远了，所以顾客都偏好就近还车。
- A 店海淀区和 B 店朝阳区的停车场要大一些，以便可以停更多的车。
- D 店丰台区属于地广人稀的地段，去那里还车的大概都是去机场的顾客。
- 在经过统计各个门店的租出车辆数据后，需要定期地在门店之间转移车辆，但是也需要再统计每个门店平均每天的出租量。


我们还可以比较一下表 3.3.1 的最后一行数据与 $P^k$ 矩阵的数值，放在表 3.3.2 中。

表 3.3.2 初始概率与平稳概率的比较

||A店|B店|C店|D店|
|-|-|-|-|-|
|$P^1$转入总和|0.9|1.5|0.6|1.0|4.0|
|$P^k$转移概率|0.27|0.30|0.16|0.27|

直观上看：
- B 店的初始转入总和为 1.5，最大，所以 $P^k$ 的值也最大，为 0.3；
- A 店与 D 店相差不多；
- C 店的初始转入概率总和值最小，最后的平稳概率值也最小。
