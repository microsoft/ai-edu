
## 4.2 马尔可夫过程

### 4.2.1 马尔可夫性质（Markov property）

通常中文比英文更能表现出哲理来，但是在这里，我们先记住一句很有哲理的英文：

*The future is independent of the past given the present.*

**将来**只取决于**现在**，与**过去**无关。

当一个随机过程在给定当前状态及所有过去状态情况下，其未来状态的条件概率分布仅依赖于当前状态；换句话说，在给定现在状态时，它与过去状态（即该过程的历史路径）是条件独立的，那么此随机过程即具有**马尔可夫性质**。

<center>
<img src="./img/RandomWalker-2.png" width="500">

图 4.2.1 马尔可夫性质
</center>

马尔可夫性质是概率论中的一个概念，因为俄国数学家安德雷·马尔可夫（Andrey Markov, 1856-1922）得名。在大学期间，马尔可夫表现优异，师从了前面提到的俄国数学的重要奠基人契比雪夫，可以说是契比雪夫和他的弟子们的成就让俄国在数学世界中占有了一席之地。马尔可夫的主要工作集中在数论和概率论的研究方面，尤其是概率论方面，圣彼得堡学派对概率论这门学科贡献很大，马尔可夫在概率论领域成果颇多，从一开始对大数定理和中心极限定理的研究，逐渐发展到对随机变量的研究，终于提出了大名鼎鼎的马尔可夫链概率（在稍后讲解）模型。


用公式表示为：

$$
\mathbb P[S_{t+1}|S_t]=\mathbb P[S_{t+1}|S_1,S_2,...,S_t] \tag{4.2.1}
$$

翻译成普通话：给定当前状态 $S_t$ 时，下个状态 $S_{t+1}$ 的发生概率，等于给定以前所有状态下 $S_{t+1}$ 的发生概率。这实际上就是忽略了 $S_1, S_2, S_{t-1}$ 的存在。


在上面的图 4.1.2 中，假设醉汉到了 C 单元，但是它究竟是如何到了 C 单元的，我们并不关心，我们只知道他的下一个状态是 B,C,D 之一。

在前面的租车还车问题的例子中，一辆车出现在 B 门店，我们只关心那么它的下一个出现点在哪里，而不管它从哪个门店转移过来的。

从本节开始，我们把 A,B,C,D 这些门店、单元等等统称为状态，状态之间的过渡成为状态转移。状态转移的概率定义为：

$$
P_{ss'}=\mathbb P[S_{t+1}=s'|S_t=s] \tag{4.2.2}
$$

可以理解为当 $t$ 时刻的状态 $S_t$ 为 $s$ 时（$s$ 可以是上述具体问题中的 A,B,C,D 等），转移到下一个时刻 $t+1$ 时的状态 $S_{t+1}$ 是 $s'$ 的概率（$s'$ 同样可以是上述具体问题中的 A,B,C,D 等）。

举一个具体的例子，在醉汉回家问题中，如果 $s=C, s'=D$，则：

$$
P_{ss'}=P_{CD} =\mathbb P[S_{t+1}=D|S_t=C]=0.4
$$

同理有：

$$
P_{CC} =\mathbb P[S_{t+1}=C|S_t=C]=0.2
\\
\\
P_{CB} =\mathbb P[S_{t+1}=B|S_t=C]=0.4
$$

另外，在前面的租车还车问题中，我们已经学习过了转移概率矩阵，这同样可以应用到马尔可夫性质中的状态转移，所以改名为状态转移矩阵（State Transition Matrix），公式形式相同，如式（4.2.3）。

$$
\qquad \qquad \quad [to]
\\
P = [from]
\begin{pmatrix}
P_{11} & \cdots & P_{1n}
\\
\vdots & \ddots & \vdots
\\
P_{n1} & \cdots & P_{nn}
\end{pmatrix}
\tag{4.2.3}
$$

其中：$\sum_{j=1}^n P_{ij}=1, \ i=1,...,n$，即一行中所有的值相加为 1。

马尔可夫性质对于数学后续的发展起到了基石的作用，后续很多数学家在此基础上发展出了更多的扩散模型和随机过程模型。

### 4.2.2 马尔可夫过程（Markov Process）

具有**马尔可夫性质**的过程通常称之为**马尔可夫过程**。它是一个无记忆的随机过程，由具有马尔可夫性质的随机状态序列构成。由于时间和状态的特性，又可以分成几种情况，列在表 4.2.1 中。

表 4.2.1 不同类型的马尔可夫过程

||时间连续|时间离散|
|-|:-:|:-:|
|**状态连续**|马尔可夫过程|-|
|**状态离散**|连续的马尔科夫链|马尔可夫链|

- 时间和状态都连续的，叫做**马尔可夫过程**（严格意义上的），比如：一个电子的随机运动。
- 时间和状态都不连续的，叫做**马尔可夫链**，比如：棋类游戏。在棋类比赛中，虽然时间在流动，但是它只存在于比赛者的思考过程中，盘面没有任何变化，除非比赛者移动或部署了棋子。
- 时间连续、状态离散的，叫做**连续时间的马尔科夫链**，比如：一个扫地机器人的工作过程，它在一段连续时间内一直处于“扫地”状态，在另外一段连续时间内处于“充电”状态。

举几个例子：

- 马尔可夫链蒙特卡罗
  将马尔科夫链与蒙特卡洛方法结合，把经典蒙特卡洛方法中统计独立的特性改造为马尔科夫性质的统计相关，在某些情况下对随机现象的建模效果更佳，这种方法在图像处理、信号处理、金融分析等领域有广泛应用。

- 隐马尔可夫模型
  是对马尔可夫模型的扩展，这种模型的思想核心是把马尔科夫的状态转移设定为未知的隐含量，通过可观测的状态转移过程来估计隐含的状态，然后再用隐含状态来预计未来的变化，利用这种方法发现很多实际问题能够得到有效的建模，典型的应用包括了语音识别、生物信息科学的DNA分析和故障诊断等领域。

- 马尔可夫随机场
  给随机场定义一种马尔可夫性质，即随机场中每个位置的属性定义是马尔可夫性的，简单理解就是随机场中每个位置的属性只与邻近的位置有关，与其他位置无关。这种方法被应用于图像分割取得较好效果。


由于具有马尔可夫性质，所以马尔可夫过程是一个无记忆的随机过程，由“状态-概率”二元组组成：$<S,P>$。

- $S$ 为有限的状态空间集，s_i表示时间步i的状态，其中$S=\{s_1,s_2,...s_n\}$。
- $P$ 为状态转移矩阵，$P_{ss'}=\mathbb P[S_{t+1}=s'| S_t=s]$。

### 4.2.3 马尔科夫链（Markov Chain）

是一种最简单的马尔可夫过程（非严格意义上的），专指离散指数集的马尔可夫过程。经典的马尔可夫链主要是研究当前状态和未来状态之间的转移概率，并可以计算出多次试验之后的每个状态的概率分布，从而将看起来毫无规律的一些随机现象变成了整体有序的状态变化。

上述的醉汉回家以及租车还车的过程，都是马尔可夫链的具体例子。

马尔可夫链极其扩展被广泛的应用：
- 如物理学和化学中，马尔可夫链和马尔可夫过程被用于对动力系统进行建模，形成了马尔可夫动力学（Markov dynamics）。
- 在排队论（queueingtheory）中，马尔可夫链是排队过程的基本模型。
- 在信号处理方面，马尔可夫链是一些序列数据压缩算法，例如Ziv-Lempel编码的数学模型。
- 在金融领域，马尔可夫链模型被用于预测企业产品的市场占有率。

有时候当一个问题的连续的时间和状态不容易分析的时候，可以把它近似为离散的时间和状态，转变成马尔可夫链来分析解决。

那么哪些问题可以用马尔可夫过程来分析呢？笔者根据自己的理解举例说明。读者也许有自己的理解，大家可以一起讨论。

#### 正例

- 象棋残局
  当前盘面上的棋力、位置、先后手，决定了后面的局势发展。换一句话说，一副残局摆在那里，任何人都可以继续下棋直至结束，输赢只与当前盘面（和棋手水平）有关，与开局阶段的过程以及哪个棋手形成的残局无关。

- 租车还车
  车辆归还的位置只与它昨天出租的位置相关，与前天的情况无关。其实其根本原因是由于顾客的情况是随机的，所以和车辆无关。

- 醉汉回家
  醉汉的位置只与他上一步的位置有关，与历史足迹无关。

- 冰面行走
  一个人在冰面上一步一步缓慢行走，有时候需要绕过一些看上去很危险薄冰，还有可能走到一半感觉危险觉得返回出发点。

- 从袋中有回放地取球
  布口袋中放有很多不同颜色的球，从中任意取出一个球，记录颜色，放回到口袋中，摇匀，再取一次。

#### 反例

- 桥牌残局
  当前手中剩余的牌，不能让庄家决定后面如何继续打，必须依赖前面的叫牌和打牌顺序。换一句话说，打了一半的牌，别人是无法接手的，只能自己打完。

- 天气预报
  今天是晴天，明天是雨天或阴天，类似这种情况，不是严格的马尔可夫性质。因为对于气候来说，是一个长时间积累、酝酿、变化的过程。当然，也可以根据统计数据硬性计算出一个转移概率，但是可靠性很低。

- 股票价格
  股价的涨跌是没有概率可言的，它是一个金融市场的规律，与股票本身以及外部环境等都关系紧密。我们常看到某些文章中说：三天大阳线，叫做三羊开泰，后市看好。假设这个描述是对的，那么明天的涨跌要依赖前三天的状态，而不是前一天的状态，这和马尔可夫性质定义不符。

- 轨道冰车
  冬奥会上的比赛项目，一个人或者两个人坐在冰车里，沿着轨道滑行，比赛到达终点时谁用的时间短。冰车的轨道可以看作是一维的，冰车由于坡度下滑，位置不断向前移动，没有一点儿可能是向后或者滑出轨道。

- 从袋中没有回放地取球
  布口袋中放有很多不同颜色的球，从中任意取出一个球，记录颜色；从口袋中还剩下的球中再取一次，记录......则当前取出球的颜色和以前每一次取出球的颜色都有关，而不仅仅与上一次的结果相关。

### 4.2.4 马尔科夫链收敛

在本节的醉汉回家问题中，马尔科夫链是有终止状态的，或者是回到家，或者是被野兽吃掉。这种情况叫做周期性的马尔可夫链。

在上节的租车问题中，没有终止状态，只要车不坏，就会在 4 个门店之间不断移动。一个有趣的现象是，当迭代了28次后就已经**收敛**到很小的误差了。可以认为在经过多次的 “租、还、租、还” 循环后，某辆车在四个门店的出现概率（精确到两位小数）固定为：$[0.27,\ 0.30,\ 0.16,\ 0.27]$。

这种情况就称为非周期性的**马尔科夫链收敛**。

马尔科夫链要能收敛，需要满足以下条件：
1. 可能的状态数有限。
2. 状态间的转移概率固定不变。
3. 能从任意状态经过 1 到 k 步转变到任意状态，即任意两个状态之间是连通的。
4. 不能是简单的循环，例如 $A \to B \to C \to A \to B \to C$。

细致平衡条件（Detailed-Balance Condition）：给定一个马尔可夫链，分布$\pi$和概率转移矩阵$P$，如果下面等式成立:

$$
\pi=\pi P \tag{4.2.4}
$$

则此马尔可夫链具有一个平稳分布（Stationary Distribution)，其中 $\pi$ 是最后的平稳分布矢量，比如租车问题中 $\pi=(0.27, \ 0.30, \ 0.16, \ 0.27)$，其和为 1，表示全概率。

有的读者可能想不通为什么会有平稳分布的情况出现，我们举一个更简单的例子来说明。

假设城市化进程中，农村人转移为城市人的概率为 0.3，城市人转移为农村人的概率为 0.1。那么从表面上来看，越来越多的农村人会转移到城市来，最后农村就没人了。

列出这个问题的转移状态矩阵和最后的平稳状态收敛矩阵在表 4.2.2 中。

表 4.2.2 状态转移与平稳状态

|初始状态|农村|城市|$\to$|平稳状态|农村|城市|
|-:|-:|-:|-:|-|-:|-:|-:|
|**农村**|0.7|0.3||**农村**|0.25|0.75|
|**城市**|0.1|0.9||**城市**|0.25|0.75|

请读者注意，这里的平稳状态并不是说双方转移的概率发生了改变，而是对于初始人口分布来说，最终的效果是这样的。

假设最初农村有 10 万人口，城市有 2 万人口，用初始人口分布乘以平稳状态的转移概率，可以得到：

$$
(100000,20000)
\begin{pmatrix}
0.25 & 0.75
\\\\
0.25 & 0.75
\end{pmatrix}
=(30000,90000)
\tag{4.2.5}
$$

最终农村为 30000 人，城市为 90000 人。

如果按照初始的转移概率迭代（即每次都用人口分布乘以初始转移概率） 23 次的结果如表 4.2.3。

表 4.2.3 人口转移迭代过程

|迭代次数|农村人口|城市人口||迭代次数|农村人口|城市人口|
|:-:|-:|-:|-|:-:|-:|-:|
|0|100000|20000||12|30152|89848|
|1|72000 |48000||13|30091|89909|
|2|55200 |64800||14|30055|89945|
|...|...|...||...|...|...|
|9|30705 |89295||21|30002|20000|
|10|30423|89577||22|30001|89999|
|11|30254|89746||23|30000|90000|

结果和式（4.2.5）一样。虽然越来越多的农村人移动到城市，但是并非绝对数量，而是有个比例的。比例虽然大，但是基数却越来越小（农村人逐渐变少），所以最后绝对数量会持平，即：$30000 \times 0.75 = 90000 \times 0.25 = 225000$，即每年有 22500 人从农村到城市，但是有相同的人数从城市到农村，双方保持平稳。

现在可以用人口流动问题的具体例子再解释一下式（4.2.4）的含义。在此问题中，$\pi=(\pi_1 \ \pi_2)$，对式（4.2.4）实例化则有：

$$
(\pi_1 \ \pi_2)=(\pi_1 \ \pi_2)
\begin{pmatrix}
0.7 & 0.3
\\\\
0.1 & 0.9
\end{pmatrix}
\tag{4.2.7}
$$

对式（4.2.7）列方程组求解：

$$
\begin{cases}
\pi_1 = 0.7\pi_1 + 0.1\pi_2
\\
\pi_2=0.3\pi_1+0.9\pi_2
\\
\pi_1+\pi_2=1
\end{cases}
$$

解得：$\pi_1=0.25, \pi_2=0.75$，与表 4.2.2 所示的矩阵迭代收敛值相同。
