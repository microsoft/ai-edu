## 学生问题

### 1 提出问题

在学生学习的模型中有很多状态，如何确定某个状态比另一个状态好呢？或者说如何比较两个状态的好坏呢？因为从直觉上讲，学生在 C1,C2,C3 的状态明显要比 Game 状态好，但是如何能用数字的大小来体现这种好坏关系呢？

在上一节中，已经有了分幕、奖励、回报的概念，这一节中，将会利用这些基础概念来定义每个**状态价值函数**，从而可以比较状态之间的好坏。

### 2 状态价值函数（State Value Function）

在上一节通过对 $G$ 的计算，以及对状态图的分析理解，我们似乎已经得到了一些启示：距离终点越近的状态，越接近于成功，它的状态价值就越高，似乎用 $G$ 值就可以表示该时刻的状态价值。

但是，会有一个麻烦出现：每个学生走的路径都不完全一样，状态图虽然是有向的，但是由于环状转移的原因，一个状态在一个序列中可能会出现多次。比如 C1 状态，有三种情况可以到达：

1. 最开始上第一次课时；
2. 从游戏状态返回时；
3. 从休息状态返回时。

而以 C1 开始的路径又可以有很多种，如表 1 所示。

表 1 以 C1 开始的 $G$ 值的计算

||分幕采样序列|回报值计算（$\gamma=1$）|
|-|-|-|
|1|C1-C2-C3-Pass-End|$G_{C1}=-2-2-3+10+0=3$|
|2|C1-Game-Game-C1-C2-End|$G_{C1}=-2-1-1-1-2-2+0=-9$|
|3|C1-C2-C3-Rest-C2-C3-Pass-End|$G_{C1}=-2-2-3+1-2-2+10+0=0$|
|4|C1-C2-C3-Rest-C1-Game-Game-C1-C2-End|$G_{C1}=-2-2-2+1-2-1-1-2-2+0=-13$|

这样的话，一个状态 C1 就可能有 4 个 $G$ 值，我们用哪个当作其价值函数呢？另外，仔细观察 $G$ 的表达式，它只与时刻及奖励有关，没有体现出状态来。

考虑到以上两点，定义状态价值函数如下：

$$
\begin{aligned}
V_t(s) &= \mathbb E [G_t | S_t = s]
\\\\
&=\mathbb E [ R_{t+1}+\gamma R_{t+2}+\gamma^2 R_{t+3}+ \gamma^3 R_{t+4}+ \cdots]
\end{aligned}
\tag{1}
$$

### 3 数学期望

简单地回忆一下**数学期望**的概念。

一个正常的六面的骰子，投出去后可以得到 [1,2,3,4,5,6] 六种结果，而且概率相等，那么这个骰子的期望值是 $(1+2+3+4+5+6)/6=3.5$。哈哈，读者可能会发现 3.5 这个数子，骰子无法投出来，所以它只是一种定义。

但是，一个不正常的骰子，比如 [4,5,6] 出现的概率 $p$ 都是 $\frac{1}{5}$，而 [1,2,3] 出现的概率 $p$ 都是 $\frac{2}{15}$，那么它的数学期望是：

$$
\begin{aligned}
\mathbb E[骰子]&=\sum_{i=1}^6 p_i V_i
\\\\
&= \frac{2}{15} \times 1+\frac{2}{15} \times 2+\frac{2}{15} \times 3+\frac{1}{5} \times 4+\frac{1}{5} \times 5+\frac{1}{5} \times 6
\\\\
&=3.8
\end{aligned}
$$

那么，在状态价值函数中，数学期望没有定义权重或概率，所以每一幕的数据都是同等价值的，因此，状态价值函数就是多幕的 $G$ 的算术平均值。

以表 1 中的数据为例：$V(C1)=[3 +(-9)+0+(-13)]/4=-4.75$

但是，只有 4 幕采样并不能准确计算出真正的期望值，因此，我们需要更多的采样。一般情况下，采样的数量级应该是成千上万的，才会得到一个比较稳定的数学期望值。

### 4 计算状态价值函数

