
### 马尔可夫奖励过程中的贝尔曼方程

<center>
<img src="./img/Bellman.png">

图 1 贝尔曼公式推导
</center>

- 左图：在 $s_a$ 状态得到 $R(s)$ 的表达式。
  在使用**注重过程**的奖励函数定义方式时，从$s_a$ 转移到 $s_b,s_c$ 的过程中，分别可以得到 $r_1,r_2$ 的奖励，则 $s_a$ 的奖励函数定义为一种期望：$R(s_a)=\mathbb E[R_{Sa}|S_t=s_a] = p_1 \cdot r_1+p_2 \cdot r_2$。
- 右图：在 $s_a$ 状态得到 $G_{t+1}$ 的表达式。
  当 $S_t=s$ 时，即在 $s_a$状态下，只能确定 $G_{t}=G_a$，不能确定$G_{t+1}$，因为不知道下一步会转移到哪个状态，是 $s_b$ 还是 $s_c$？
  所以，在 $s_a$ 状态时，$G_{t+1}$ 只能用转移概率（即 $p_1,p_2$）与下层状态 $s_b,s_c$ 的 $G$ 值（即 $G_a,G_b$）的乘积来表示，相当于在 $S_t=s_a$ 时，对 $G_{t+1}$ 求一次期望（带权重的平均值）：$G_{t+1}=\mathbb E[G_{b,c}|S_t=s_a]=(p_1 \cdot G_b|S_{t+1}=s_b)+(p_2 \cdot G_c|S_{t+1}=s_c)$。一旦确定到达 $s_b,s_c$ 状态后，$S_t=s_a$ 的条件就可以去掉了，分别用 $S_{t+1}=s_b,S_{t+1}=s_c$ 代替。


做实例化推导之前，针对图 1，先给出一些必要的定义。

状态集定义：

$$
s_a \in s, \ (s_b,s_c) \in s'
$$

其中：$s$ 等同于 $S_t$，$s'$ 等同于 $S_{t+1}$。

由价值函数的定义：
$$
V(s)=\mathbb E [G_t|S_t=s] \tag{1}
$$
可以得到图 1 中状态 $S_a, S_b, S_c$ 的价值函数的实例化表示：
$$
\begin{aligned}
V(s_a)&=\mathbb E [G_a|S_t=s_a]  & (2.1)
\\
V(s_b)&=\mathbb E [G_b|S_{t+1}=s_b]  & (2.2)
\\
V(s_c)&=\mathbb E [G_c|S_{t+1}=s_c]  & (2.3)
\end{aligned}
\tag{2}
$$

在本例中，如果 $V(s)=V(s_a)$，则 $V(s_b),V(s_c) \in V(s')$。

图 1 中状态转移概率的实例化表示：

$$
\begin{aligned}
p_1 &= p(s_b|s_a)=P(s'|s), \ (s=s_a,s'=s_b) &(3.1)
\\
p_2 &= p(s_c|s_a)=P(s'|s), \ (s=s_a,s'=s_c) &(3.2)
\end{aligned}
\tag{3}
$$

图 1 中奖励函数的实例化表示：

$$
\begin{aligned}
r_1 &= r(s_a,s_b)=R(s,s'), \ (s=s_a,s'=s_b) &(4.1)
\\
r_2 &= r(s_a,s_c)=R(s,s'), \ (s=s_a,s'=s_c) &(4.2)
\end{aligned}
\tag{4}
$$

该奖励函数的定义属于**注重过程**的定义方式，即定义在状态转移过程中。而此时状态 $S_a$ 的奖励为：
$$
R_{t+1}=p_1 \cdot r_1+p_2 \cdot r_2 \tag{5}
$$


推导

$$
\begin{aligned}
V(s)&=\mathbb E [G_t|S_t=s]
\\
&=\mathbb E[R_{t+1}+\gamma R_{t+2}+\gamma^2 R_{t+3}+\cdots|S_t=s]
\\
&=\mathbb E[R_{t+1}+\gamma (R_{t+2}+\gamma R_{t+3}+\cdots)|S_t=s]
\\
&=\mathbb E[R_{t+1}+\gamma G_{t+1}|S_t=s]
\\
&= \underbrace{ \mathbb E[R_{t+1}|S_t=s]}_A + \gamma \underbrace{\mathbb E[G_{t+1}|S_t=s]}_B
\end{aligned}
\tag{6}
$$

式 6 的 $A$ 部分：

$$
\begin{aligned}
A & = \mathbb E[R_{t+1}|S_t=s]
\\
({\footnotesize 实例化}\to) &= \mathbb E[R_{Sa}|S_t=s_a]
\\
({\footnotesize 图 1 左图} \to )&= p_1 \cdot  r_1+p_2 \cdot r_2 
\\
({\footnotesize 式3,4} \to) &=p(s_b|s_a) \cdot r(s_a,s_b)+p(s_c|s_a) \cdot r(s_a,s_c)
\\
({\footnotesize 抽象化} \to) &=\sum_{s'} P(s'|s) \cdot R(s,s') \to R(s)
\end{aligned}
\tag{7}
$$

式 6 的 $B$ 部分：

首先要注意的一个问题是，B 不等于 $V(s')$，因为按式 6 的第一行，$V(s')=\mathbb E[G_{t+1}|S_{t+1}=s'] \ne \mathbb E[G_{t+1}|S_t=s]$。

$$
\begin{aligned}
B&=\mathbb E\big[G_{t+1}|S_t=s \big ] 
\\
({\footnotesize 实例化} \to)&=\mathbb E \big[\mathbb E[G_{b,c}|S_t=s_a] \big ] 
\\
({\footnotesize 图1右图} \to)&= \mathbb E\big[(p_1 \cdot G_{b}|S_{t+1}=s_b) + (p_2\cdot G_{c}|S_{t+1}=s_c)\big]
\\
({\footnotesize 期望加法变换} \to)&=\mathbb E\big[p_1\cdot G_{b}|S_{t+1}=s_b]+\mathbb E[p_2\cdot G_{c}|S_{t+1}=s_c\big]
\\
({\footnotesize 提出常数} p_1,p_2\to)&=p_1 \cdot \mathbb E[G_{b}|S_{t+1}=s_b]+ p_2 \cdot \mathbb E[G_{c}|S_{t+1}=s_c]
\\
({\footnotesize 式2} \to)&= p(s_b|s_a) \cdot V(s_b) + p(s_c|s_a) \cdot V(s_c)
\\
({\footnotesize 抽象化} \to)&= \sum_{s'} P(s'|s)V(s')
\end{aligned}
\tag{8}
$$

所以式 6 最终为：

$$
\begin{aligned}
V(s) &= \mathbb E[R_{t+1}|S_t=s] + \gamma \mathbb E[G_{t+1}|S_t=s]
\\
&=\sum_{s'} P(s'|s) R(s,s')+ \gamma \sum_{s'} P(s'|s)V(s') & (9.1)
\\
&=\sum_{s'} P(s'|s)[R(s,s')+\gamma V(s')] &(9.2)
\\
&= R(s)+ \gamma \sum_{s'} P(s'|s)V(s')=R_s+ \gamma \sum_{s'} P_{ss'}V(s') &(9.3)
\end{aligned}
\tag{9}
$$

- 在**针对过程定义奖励函数**的问题中，使用式 9.2 比较方便，因为 $R(s,s')$ 是定义在从 $s\to s'$ 的转移过程上。这是 Richard S. Sutton and Andrew G. Barto 书中的写法。
- 在**针对状态定义奖励函数**的问题中，使用式 9.3 比较方便，因为 $R(s)$ 是直接定义在状态 $s$ 上。这是 David Silver 课件中的写法。


如果针对图 1，状态 $s_a$ 的价值函数实例计算公式为：

$$
\begin{aligned}
V(s_a)&=(p_1 \cdot r_1 + p_2 \cdot r_2) + \gamma[p_1 \cdot V(s_b) + p_2 \cdot V(s_c)]
\\
&=R(s)+\gamma[p_1 \cdot V(s_b) + p_2 \cdot V(s_c)]
\end{aligned}
$$

也就是说，一个状态 $s$ 的价值函数 $V(s)$ 由它的下游状态 $s'$ 的价值函数 $V(s')$ 和转移概率 $P(s,s')$ 以及转移过程中的奖励 $R(s,s')$ 构成。

Bellman Equation for MRP

<center>
<img src="./img/student-3.png" width="500">

图 2
</center>

图 2 中，每个状态下方都用括号表示了该状态的序号，比如 C1(1) 表示 $v_1$。以状态 C3 为例，根据式 9.3，可以得到其价值函数为：

$$
\begin{aligned}
v_3&=R(C3)+\gamma[P_{C3,Pass} \cdot V(Pass) + P_{C3,Rest} \cdot V(Rest)]
\\
&=-2+ (0.6 v_4 + 0.4 v_5), &(\gamma=1)
\end{aligned}
$$

同理可以得到其它所有状态的价值函数表达式，列出方程组如下：

$$
\begin{cases}
v_0=-1+0.9v_0+0.1v_1 & (10.1)
\\
v_1=-2+0.5v_0+0.5v_2 & (10.2)
\\
v_2=-2+0.8v_3+0.2v_6 & (10.3)
\\
v_3=-2+0.6v_4+0.4v_5 & (10.4)
\\
v_4=10+v_6 & (10.5)
\\
v_5=1+0.2v_1+0.4v_2+0.4v_3 & (10.6)
\\
v_6=0 & (10.7)
\end{cases}
\tag{10}
$$

这是一个七元一次方程组，肯定有解。先简化式 10 中的各项，得到新的表达式：

$$
\begin{cases}
v_0=v_1-10 & (11.1)
\\
v_1=-2+0.5v_0+0.5v_2 & (11.2)
\\
v_2=0.8v_3-2 & (11.3)
\\
v_3=0.4v_5+4 & (11.4)
\\
v_4=10 & (11.5)
\\
v_5=1+0.2v_1+0.4v_2+0.4v_3 & (11.6)
\\
v_6=0 & (11.7)
\end{cases}
\tag{11}
$$

将 $(11.1)(11.2)(11.3)(11.4)$ 都变成 $v_3$ 的表达式，带入$(11.6)$ 的两侧，可以得到：

$$
2.5v_3-10=1+0.2(0.8v_3-16)+0.4(0.8v_3-2)+0.4v_3
$$

得到：$v_3=4.321$

所以，最终的结果为：

$$
\begin{cases}
v_0=-22.543 \approx -22.5
\\
v_1=-12.543 \approx -12.5
\\
v_2=1.457 \approx 1.5
\\
v_3=4.321 \approx 4.3
\\
v_4=10
\\
v_5=0.803 \approx 0.8
\\
v_6=0
\end{cases}
\tag{12}
$$

读者可以用式 12 的结果验证式 10 中的任意等式。


### 矩阵法

观察式 10 方程组，可以把它变形为：

$$
\begin{bmatrix}
v_0
\\
v_1
\\
v_2
\\
v_3
\\
v_4
\\
v_5
\\
v_6
\end{bmatrix}
= \
\begin{bmatrix}
-1
\\
-2
\\
-2
\\
-2
\\
10
\\
1
\\
0
\end{bmatrix}
+\gamma 
\begin{bmatrix}
0.9v_0+0.1v_1
\\
0.5v_0+0.5v_2
\\
0.8v_3+0.2v_6
\\
0.6v_4+0.4v_5
\\
v_6
\\
0.2v_1+0.4v_2+0.4v_3
\\
0
\end{bmatrix}
\tag{13}
$$


关于式 13：

- 等式左侧的部分，就是状态值的向量，可以写成 $V_s$。
- 等式右侧的第一项，就是状态上的奖励值组成的向量，可以写成 $R_s$。
- 等式右侧的第二个矩阵，又可以写成：

$$
\begin{bmatrix}
0.9 & 0.1 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0
\\
0.5 & 0.0 & 0.5 & 0.0 & 0.0 & 0.0 & 0.0
\\
0.0 & 0.0 & 0.0 & 0.8 & 0.0 & 0.0 & 0.2
\\
0.0 & 0.0 & 0.0 & 0.0 & 0.6 & 0.4 & 0.0
\\
0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0
\\
0.0 & 0.2 & 0.4 & 0.4 & 0.0 & 0.0 & 0.0
\\
0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0
\end{bmatrix}
\begin{bmatrix}
v_0
\\
v_1
\\
v_2
\\
v_3
\\
v_4
\\
v_5
\\
v_6
\end{bmatrix}
\tag{14}
$$

式 14 等式右侧的第一个矩阵就是该问题的状态转移矩阵 $P_{ss'}$，第二个矩阵是状态值向量 $V_s$，于是，式 9 可以变成：
$$
V_s = R_s+ \gamma P_{ss'}V_s \tag{15}
$$

从式 9 直接看过来，式 15 等式右侧的 $V_s$ 应该是 $V_{s'}$ 才对，即 $V_s = R_s+\gamma P_{ss'}V_{s'}$。但是经过上述的实例化推导，读者可以理解所谓的 $V_{s'}$ 是在时间维度上的定义，表示下一步的状态；而在空间上，由于状态值一旦确定就不会变化，并没有 $s'$ 的概念。

比如：
- 式 10.4，$v_3=-2+ (0.6 v_4 + 0.4 v_5)$ 中，$V_s=v_3,V_{s'}=\{v_4,v_5\}$，$v_5$ 是 $v_3$ 的后续状态。
- 式 10.6，$v_5=1+0.2v_1+0.4v_2+0.4v_3$ 中，$V_s=v_5,V_{s'}=\{v_1,v_2,v_3\}$，$v_3$ 是 $v_5$ 的后续状态。

两者在不同的马尔可夫过程中互为后续状态，所以实际上并没有 $V_{s'}$ 的概念。

式 15 可以变形，并最终解出 $V_s$：

$$
\begin{aligned}
V_s &= R_s+ \gamma P_{ss'}V_s
\\
V_s - \gamma P_{ss'}V_s &= R_s
\\
(I-\gamma P_{ss'})V_s&=R_s, &(I \ {\footnotesize 是对角矩阵})
\\
V_s&=(I-\gamma P_{ss'})^{-1}R_s
\end{aligned}
\tag{16}
$$

式 16 中，等式右侧的值都是已知的，所以可以得出 $V_s$ 的数学解析解。

### 迭代法（动态规划）