
## 7.8 单数组通用迭代法

### 7.8.1 双数组迭代 vs. 单数组原地更新

观察上一小节中迭代法的代码，读者会发现我们“聪明地”使用了两个数组，一个是 V_old 来存储上一轮迭代的状态数值，另一个是 V_new 来计算本轮迭代的状态数值，这样可以保证所有的 V_new 都是从上一次迭代的 V_old 计算得到，很“干净”。

但是，真的需要这么“干净”吗？如果把式（7.6.3）改成（等式前后都是 $v_{[k]}$，没有 $v_{[k+1]}$）：

$$
v_{[k]}(s) = R(s)+ \gamma \sum_{s'} p_{ss'}v_{[k]}(s')
\tag{7.8.1}
$$

会如何呢？

一个不怎么伟大的程序员也可以立刻写出如下代码：

【代码位置：LifeCycle_3_SingleArray_Iteration.py】

```Python
# 单数组线性迭代法
def single_array_iteration(dataModel, gamma, max_iteration):
    print("单数组线性迭代法")
    helper.print_seperator_line(helper.SeperatorLines.long)
    V = np.zeros(dataModel.N)   # 初始化为全 0
    count = 0   # 迭代计数器
    while (count < max_iteration):   # 避免不收敛而导致while无限
        count += 1          # 计数器+1
        V_old = V.copy()    # 备份上一次的迭代值用于检查收敛性
        # 线性方程组
        V[0] = dataModel.R[0] + gamma * (0.2 * V[0] + 0.8 * V[1])
        V[1] = dataModel.R[1] + gamma * (0.6 * V[0] + 0.4 * V[2])
        V[2] = dataModel.R[2] + gamma * (0.1 * V[1] + 0.9 * V[3])
        V[3] = dataModel.R[3] + gamma * (0.1 * V[1] + 0.2 * V[4] + 0.7 * V[5])
        V[4] = dataModel.R[4] + gamma * (0.2 * V[1] + 0.5 * V[2] + 0.3 * V[3])
        V[5] = dataModel.R[5] + gamma * V[6]
        V[6] = dataModel.R[6]
        if np.allclose(V_old, V):   # 检查收敛
            break
    print("迭代次数 :", count)
    return V
```

与双数组方法相比，就是把线性方程组等式前后的 V_next,V_old 统一成 V 了。之所以还有 V_old=V.copy()，是为了检查收敛性，在计算过程中，并没有使用到 V_old。

运行结果如下：

```
单数组线性迭代法
========================================
迭代次数 : 36
状态价值函数计算结果(数组) : [-5.99 -2.24  3.38  2.9   4.11 -1.    0.  ]
Bug:        -5.99
Coding:     -2.24
Test:       3.38
Review:     2.9
Refactor:   4.11
Merge:      -1.0
End:        0.0
```
读者会惊奇地发现，迭代次数从以前的 65 次变成了 36 次即达到收敛状态。这是为什么呢？

原因是这样的：观察线性方程组中的代码，当第一行计算完 V[0] 后（这里的方括号表示状态价值函数数组，V[0] 实际上是 $v_0$），第二行在计算 V[1] 时立刻就用到了新的 V[0]，......，计算 V[4] 时就已经用到了最新的 V[1],V[2],V[3]。所以，收敛的速度变快了。在处理动态规划问题时，一般都使用这种原地更新法（in place update）。

有兴趣的读者可以修改一下 V[0]~V[6] 的计算顺序，看看是否还可以提高一点儿迭代效率。如果前后依赖比较强的话，更改遍历计算的顺序会提高性能；但如果是交叉依赖，就不那么明显了。

### 7.8.2 通用的迭代实现

7.8.1 节中的单数组迭代法又把矩阵运算的过程变成逐行计算了，它的好处是不用维护状态转移矩阵，缺点是只针对本案例有效。当换一个应用场景式，就需要重新书写算法代码来实现公式（7.6.3）。读者可以尝试思考与练习中的第 1 题，看看如果把逐行计算变成矩阵运算，还能不能做到迭代 36 次收敛。

但是，有很多时候由于状态成千上万，没有可能写出状态转移矩阵来，对于人类来说，手工维护一个 $20 \times 20$ 的矩阵，已经是极限了，需要非常小心才能不出错。

所以，最佳设计是结合上面两者的优点，只需要得到在某个状态下转移到可能达到的下游状态的列表，而不是转移到所有状态（包括不能达到的状态即概率为 0）的矩阵。

举例来说，在本问题中，状态转移矩阵是这样定义的：

```Python
# 状态转移概率
P = np.array(
    [   # B   C    T    R    F    M    E    
        [0.2, 0.8, 0.0, 0.0, 0.0, 0.0, 0.0],    # Bug 
        [0.6, 0.0, 0.4, 0.0, 0.0, 0.0, 0.0],    # Coding
        [0.0, 0.1, 0.0, 0.9, 0.0, 0.0, 0.0],    # Test (CI)
        [0.0, 0.1, 0.0, 0.0, 0.2, 0.7, 0.0],    # Review
        [0.0, 0.2, 0.5, 0.3, 0.0, 0.0, 0.0],    # reFactor
        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],    # Merge
        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]     # End
    ]
)
```
其中第二行表示从 状态 Coding 到其它所有 7 个状态的转移概率，但其中有些状态是达不到的，所以只有两个值大于 0，是一个稀疏矩阵：
```
[0.6, 0.0, 0.4, 0.0, 0.0, 0.0, 0.0],    # Coding
```
对于这种情况，有必要定义另外一种通用的数据结构，来解决稀疏问题和书写困难问题：

【代码位置：LifeCycle_4_Bellman_Iteration.py】

```Python
# 用字典代替状态转移矩阵
D = {
    States.Bug:     [(States.Bug, 0.2),     (States.Coding, 0.8)],
    States.Coding:  [(States.Bug, 0.6),     (States.Test, 0.4)],
    States.Test:    [(States.Coding, 0.1),  (States.Review, 0.9)],
    States.Review:  [(States.Coding, 0.1),  (States.Refactor, 0.2), (States.Merge, 0.7)],
    States.Refactor:[(States.Coding, 0.2),  (States.Test, 0.5),     (States.Review, 0.3)],
    States.Merge:   [(States.End, 1.0)],
    States.End:     [(States.End, 1.0)]
}

```
用第一行数据举例，它表示：在 Bug 状态下，以 0.2 的概率转移到 Bug 状态，以 0.8 的概率转移到 Coding 状态。这样的话，该状态下的数据结构中只有两条数据，而不是七条数据（另外五条数据的概率值都是 0.0）。

相应地，需要改动数据模型代码来读取这个新的数据结构：

```Python
class DataModel(object):
    def __init__(self):
        self.D = D              # 状态转移字典
        self.R = Rewards        # 奖励
        self.S = States         # 状态集
        self.N = len(self.S)    # 状态数量
        self.E = [self.S.End]   # 终止状态集

    def get_next(self, s):
        list_state_prob = self.D[s]    # 根据当前状态返回可用的下游状态及其概率
        return list_state_prob
```

因此，必须改进原始迭代法中的代码，让它可以适应通用场景。

【算法 8.8】单数组就地更新算法。

---

定义误差 $\varepsilon$
任意初始化 $V(s)$，其中 $V(s_{End})=0$
循环：
　　$V_{old}(s) \leftarrow V(s)$
　　对每一个 $s \in S$：
　　　　$V(s) \leftarrow R_{ss'}+\gamma \sum P_{ss'}V(s')$ // (式7.6.3）
　　检查收敛性 $|V_{old} - V| < \varepsilon$
　　如收敛则退出循环
返回 $V(s)$

---

该算法实际上也是实现了式（7.6.3），而下述的实现把前面的矩阵运算和数组运算变成了一个小的循环求和。

代码如下：

```Python
# 贝尔曼方程单数组更新, 式(7.3.13)
def Bellman_iteration(dataModel, gamma, max_iteration):
    print("贝尔曼方程单数组更新法")
    helper.print_seperator_line(helper.SeperatorLines.long)
    V = np.zeros(dataModel.N)
    count = 0
    while (count < max_iteration): 
        count += 1
        V_old = V.copy()    # 保存备份用于比较是否收敛
        # 遍历每一个 state，计算该状态的v(s)
        for s in dataModel.S:
            # 得到下游状态和转移概率
            list_state_prob  = dataModel.get_next(s)
            temp = 0
            for s_next, p_s_snext in list_state_prob:   # 遍历每个 s' 和 p_ss'
                temp += p_s_snext * V[s_next.value]     # 计算 sum[p·v(s')]
            # 计算 V(s) = R(s) + gamma * sum[p·v(s')]
            V[s.value] = dataModel.R[s.value] + gamma * temp
        # 检查收敛性
        if np.allclose(V, V_old):
            break
    print("迭代次数 :", count)
    return V
```

运行结果：

```
贝尔曼方程单数组更新法
========================================
迭代次数 : 36
状态价值函数计算结果(数组) : [-5.99 -2.24  3.38  2.9   4.11 -1.    0.  ]
Bug:        -5.99
Coding:     -2.24
Test:       3.38
Review:     2.9
Refactor:   4.11
Merge:      -1.0
End:        0.0
```

结果与线性方程组单数组的实现一样，都是 36 次迭代。但是，这一段代码可以适应各种应用场景，只要定义好 dataModel 中的状态转移字典即可，而不需要每次都改动算法代码。


### 思考与练习

1. 如果把代码 LifeCycle_2_Martix_Iteration.py 中的 V_new, V_old 都用单数组 V 代替，迭代次数会降低吗？为什么？
