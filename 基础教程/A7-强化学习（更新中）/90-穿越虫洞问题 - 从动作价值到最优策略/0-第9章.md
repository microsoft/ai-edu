
# 第 9 章 从动作价值到最优策略

### 温故知新

在前面的射击气球问题中，有以下几个缺陷：

- 是一个单向选择和转移的过程，最后形成了一张有向无环图。这就决定了我们可以从后向前一步步**回溯**，自下向上逐层计算状态价值函数 $v_\pi(s)$ 和动作价值函数 $q_\pi(s,a)$，直到开始状态。其计算过程是：$v_T \to q_\pi \to v_\pi \to q_\pi \to v_\pi$，如图 8.5.3 所示。

- 每个分支的细节分析起来比较多，但实际上分支之间的区别只存在于状态转移的过程的具体概率数值上。比如图 8.5.3 中的“红(2)”动作后的状态转移概率是 [0.8,0.05.0.15]，而动作“红(4)”的状态转移概率是 [0.78,0.05,0.17]。这种细节只是导致计算结果不同，但概念是相同的。

- 而另外一个重要的策略选择问题，我们暂时用“红:蓝=0.4:0.6”的固定概率，在两次射击时都是如此。但是在实际问题中，游客各有各的策略，这种统一的设定只是一种统计结果。游乐场老板虽然精明，但是游客们也不是傻子，谁都知道连续两次选择红色气球是有机会得到最高值 6 分的奖励的，只不过是能不能顺利实现的问题。

所以，本章中我们将会提出一个新的问题需要利用新的知识来解决，其特点正好可以弥补上述缺陷。

